{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-hygiene",
   "metadata": {},
   "source": [
    "# <center>Index</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-format",
   "metadata": {},
   "source": [
    "**Part 1: Set up**\n",
    "\n",
    "- Python\n",
    "- Generic Programming Structure, \n",
    "- Jupter Notebooks, \n",
    "- pillow, \n",
    "\n",
    "\n",
    "**Part 2: [Machine Learning](4.MachineLearning(ScikitLearn)/01.MachineLearning.ipynb)**\n",
    "\n",
    "1. Supervised Learning:\n",
    "    1. Regression :\n",
    "        1. [Simple Linear Regression](4.MachineLearning(ScikitLearn)/02.LinearRegression.ipynb)\n",
    "        2. [Multiple Linear Regression]()\n",
    "        3. [Polynomial Regression](4.MachineLearning(ScikitLearn)/03.MultipleRegression.ipynb)\n",
    "    \n",
    "    2. Classification : \n",
    "        1. [Logistic Regression](4.MachineLearning(ScikitLearn)/05.LogisticRegression.ipynb)\n",
    "        2. [Naive Bayes (Guassian Naive Bayes)](4.MachineLearning(ScikitLearn)/06.NaiveBayes.ipynb)\n",
    "        3. [Stochiastic Gradient Descent(Gradient Descent]()\n",
    "        4. [K-Nearest Neighbors (K-NN)]()\n",
    "        5. [Decision Tree](4.MachineLearning(ScikitLearn)/07.DecisionTree.ipynb)\n",
    "        6. [Random Forest](4.MachineLearning(ScikitLearn)/08.RandomForestClassifier.ipynb)\n",
    "        7. [Support Vector Machine (SVM)]()\n",
    "        \n",
    "2. UnSupervised Learning:\n",
    "    1. Clustering:\n",
    "        1. K-Means Clustering\n",
    "        2. Hierarchical Clustering\n",
    "        3. Hands-on Assignments\n",
    "    2. Association \n",
    "   \n",
    "3. [Reinforcement Learning]()\n",
    "    1. [Upper Confidence Bound (UCB)]()\n",
    "    2. [Thompson Sampling]()\n",
    "    3. [Temporal Difference (TD)]()\n",
    "    4. [Q-Learning]()\n",
    "    5. [Deep Adversarial Networks]()\n",
    "\n",
    "**Part 2: [Dimensionality Reduction](#)**\n",
    "\n",
    "- [Principal Component Analysis (PCA)](#)\n",
    "- [Discriminant Analysis (LDA)](#)\n",
    "- [Kernel PCA](#)\n",
    "\n",
    "\n",
    "\n",
    "**Part 3: [Deep Learning(Introduction)]()**\n",
    "- [Neural Networks]()\n",
    "- [Neural Networks (Multilayer perceptron)]()\n",
    "- [Artificial Neural Networks]()\n",
    "- [Convolutional Neural Networks]()\n",
    "\n",
    "**Part 4: <a href=\"\">Model Selection & Boosting</a>**\n",
    "\n",
    "- [Model Selection]()\n",
    "\n",
    "\n",
    "\n",
    "- Gradient-Boosted Tree (Boosted Trees)-4.MachineLearning(ScikitLearn)/09.BoostedTree.ipynb\n",
    "- One Vs Rest\n",
    "- \n",
    "\n",
    "- Support Vector Regression (SVR)\n",
    "- Evaluating Regression Models Performance\n",
    "- Kernel SVM\n",
    "- Evaluating Classification Models Performance\n",
    "\n",
    "\n",
    "**Part 5: <a href=\"\">Association Rule Learning</a>**\n",
    "\n",
    "    - Apriori\n",
    "    - Eclat\n",
    "    - Hands-on Assignments\n",
    "\n",
    "**Part 6: <a href=\"7.ComputerVision/OpenCV.ipynb\">OpenCV</a>**\n",
    "\n",
    "**Part 7: <a href=\"\">Natural Language Processing</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-milton",
   "metadata": {},
   "source": [
    "<!--div>\n",
    "ARTIFICIAL Intelligence\n",
    "#######################\n",
    "\n",
    "(AI)Introduction: \n",
    "    Introduction to Artificial Intelligence, \n",
    "    Foundations and History of Artificial Intelligence, \n",
    "    Applications of Artificial Intelligence, \n",
    "    Intelligent Agents, \n",
    "    Structure of Intelligent Agents. \n",
    "\n",
    "(AI)Introduction to Search : \n",
    "    Searching for solutions, \n",
    "    Uniformed search strategies, \n",
    "    Informed search strategies, \n",
    "    Local search algorithms and optimistic problems, \n",
    "    Adversarial Search, \n",
    "    Search for games,\n",
    "    Alpha - Beta pruning\n",
    "\n",
    "(AI)Knowledge Representation & Reasoning: \n",
    "    Propositional logic, \n",
    "    Theory of first order logic, \n",
    "    Inference in First order logic, \n",
    "    Forward & Backward chaining, \n",
    "    Resolution, \n",
    "    Probabilistic reasoning, \n",
    "    Utility theory,     \n",
    "    Hidden Markov Models (HMM), \n",
    "    Bayesian Networks.\n",
    "\n",
    "(AI)Pattern Recognition : \n",
    "    Introduction, \n",
    "    Design principles of pattern recognition system, \n",
    "    Statistical Pattern recognition, \n",
    "    Parameter estimation methods \n",
    "        - Principle Component Analysis (PCA),\n",
    "        - Linear Discriminant Analysis (LDA), \n",
    "    Classification Techniques \n",
    "        – Nearest Neighbor (NN) Rule, \n",
    "        – Bayes Classifier, \n",
    "        – Support Vector Machine (SVM), \n",
    "        – K – means clustering.\n",
    "\n",
    "(AI)MACHINE LEARNING\n",
    "####################\n",
    "    Supervised and unsupervised learning, \n",
    "    Decision trees, \n",
    "    Statistical learning models, \n",
    "    Learning with complete data - Naive Bayes models, \n",
    "    Learning with hidden data - EM algorithm, \n",
    "    Reinforcement learning,\n",
    "\n",
    "(ML)INTRODUCTION \n",
    "    – Well defined learning problems, \n",
    "    - Designing a Learning System, \n",
    "    - Issues in Machine Learning; \n",
    "\n",
    "(ML)THE CONCEPT LEARNING TASK \n",
    "    - General-to-specific ordering of hypotheses, \n",
    "    - Find-S, \n",
    "    - List then eliminate algorithm,\n",
    "    - Candidate elimination algorithm, \n",
    "    - Inductive bias\n",
    "\n",
    "(ML)DECISION TREE LEARNING \n",
    "    - Decision tree learning algorithm-Inductive bias\n",
    "    - Issues in Decision tree learning;\n",
    "\n",
    "(ML)ARTIFICIAL NEURAL NETWORKS \n",
    "    – Perceptrons, \n",
    "    - Gradient descent and the Delta rule, \n",
    "    - Adaline,\n",
    "    - Multilayer networks, \n",
    "    - Derivation of backpropagation rule Backpropagation AlgorithmConvergence,\n",
    "    - Generalization;\n",
    "\n",
    "(ML)Evaluating Hypotheses: \n",
    "    - Estimating Hypotheses Accuracy, \n",
    "    - Basics of sampling Theory, \n",
    "    - Comparing Learning Algorithms;\n",
    "\n",
    "(ML)Bayesian Learning: \n",
    "    - Bayes theorem, \n",
    "    - Concept learning, \n",
    "    - Bayes Optimal Classifier, \n",
    "    - Naïve Bayes classifier, \n",
    "    - Bayesian belief networks, \n",
    "    - EM algorithm;\n",
    "\n",
    "(ML)Computational Learning Theory: \n",
    "    - Sample Complexity for Finite Hypothesis spaces, \n",
    "    - Sample Complexity for Infinite Hypothesis spaces, \n",
    "    - The Mistake Bound Model of Learning;\n",
    "\n",
    "(ML)INSTANCE-BASED LEARNING \n",
    "    – k-Nearest Neighbour Learning, \n",
    "    - Locally Weighted Regression,\n",
    "    - Radial basis function networks, \n",
    "    - Case-based learning\n",
    "\n",
    "\n",
    "(ML)Genetic Algorithms: \n",
    "    - an illustrative example, \n",
    "    - Hypothesis space search, \n",
    "    - Genetic Programming,\n",
    "    - Models of Evolution and Learning; \n",
    "\n",
    "Learning first order rules-sequential covering algorithmsGeneral to specific beam search-FOIL; \n",
    "(ML)REINFORCEMENT LEARNING \n",
    "    - The Learning Task, \n",
    "    - Q Learning. \n",
    "\n",
    "DEEP LEARNING\n",
    "#############\n",
    "\n",
    "\n",
    "(DL)INTRODUCTION : Introduction to machine learning\n",
    "- Linear models (SVMs and Perceptrons,logistic regression)\n",
    "- Intro to Neural Nets: \n",
    "    - What a shallow network computes\n",
    "    - Training a network:\n",
    "        - loss functions, \n",
    "        - back propagation and stochastic gradient descent\n",
    "        - Neural networks as universal function approximates\n",
    "\n",
    "\n",
    "(DL)DEEP NETWORKS : History of Deep Learning- A Probabilistic Theory of Deep LearningBackpropagation and regularization, batch normalization- VC Dimension and Neural Nets-Deep Vs\n",
    "Shallow Networks-Convolutional Networks- Generative Adversarial Networks (GAN), Semisupervised Learning\n",
    "\n",
    "(DL)DIMENTIONALITY REDUCTION 9 Linear (PCA, LDA) and manifolds, metric learning - Auto\n",
    "encoders and dimensionality reduction in networks - Introduction to Convnet - Architectures –\n",
    "AlexNet, VGG, Inception, ResNet - Training a Convnet: weights initialization, batch\n",
    "normalization, hyperparameter optimization\n",
    "\n",
    "(DL)OPTIMIZATION AND GENERALIZATION : Optimization in deep learning– Non-convex\n",
    "optimization for deep networks- Stochastic Optimization Generalization in neural networks- Spatial\n",
    "Transformer Networks- Recurrent networks, LSTM - Recurrent Neural Network Language\n",
    "Models- Word-Level RNNs & Deep Reinforcement Learning - Computational & Artificial\n",
    "Neuroscience\n",
    "\n",
    "(DL)CASE STUDY AND APPLICATIONS : Imagenet- Detection-Audio WaveNet-Natural Language\n",
    "Processing Word2Vec - Joint Detection-Bioinformatics- Face Recognition- Scene UnderstandingGathering Image Captions\n",
    "\n",
    "NEURAL NETWORK\n",
    "##############\n",
    "\n",
    "(NN)Neuro Computing and Neuroscience: \n",
    "- Historical notes, \n",
    "- human Brain, \n",
    "- neuron Mode l,\n",
    "- Knowledge representation, \n",
    "- Al and NN. \n",
    "\n",
    "(NN)Learning process: \n",
    "- Supervised and unsupervised learning, \n",
    "- Error correction learning, \n",
    "- competitive learning, \n",
    "- adaptation, \n",
    "- statistical nature of the learning process.\n",
    "\n",
    "(NN)Data Processing Scaling: \n",
    "- Normalization, \n",
    "- Transformation (FT/FFT), \n",
    "- principal component analysis, \n",
    "- regression, \n",
    "- co-variance matrix, \n",
    "- Eigen values & Eigen vectors. \n",
    "\n",
    "(NN)Artificial neurons:\n",
    "- Basic Models of Artificial neurons, \n",
    "- activation Functions, \n",
    "- aggregation function, \n",
    "- single neuron computation,\n",
    "- multilayer perception, \n",
    "- least mean square algorithm, \n",
    "- gradient descent rule, \n",
    "- nonlinearly separable problems and bench mark problems in NN.\n",
    "\n",
    "(NN)Multilayered Network Architecture: \n",
    "- Back propagation algorithm, \n",
    "- heuristics for making BP-algorithm performs better. \n",
    "- Accelerated learning BP (like recursive least square, quick prop, RPROP algorithm), \n",
    "- approximation properties of RBF networks and comparison with multilayer perceptron.\n",
    "\n",
    "(NN)Recurrent Network and Temporal Feed-Forward Network: \n",
    "- Implementation with BP,\n",
    "- self-Organizing map and SOM algorithm, \n",
    "- properties of feature map and computer simulation. \n",
    "Principal component and Independent component analysis, application to image and signal processing\n",
    "\n",
    "\n",
    "(NN)Complex Valued NN and Complex Valued BP: \n",
    "- Analyticity of activation function,\n",
    "- application in 2D information processing. \n",
    "Complexity analysis of network models. \n",
    "Soft computing. \n",
    "Neuro-Fuzzy-genetic algorithm Integration\n",
    "\n",
    "(AI)Natural Language Possessing.\n",
    "###############################\n",
    "\n",
    "\n",
    "(AI)Computer vision:\n",
    "###################\n",
    "</div-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-document",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
