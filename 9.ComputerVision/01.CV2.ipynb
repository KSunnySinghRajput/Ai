{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Computer Vision 2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirment:**\n",
    "  - pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User Interface**\n",
    "\n",
    "- createTrackbar(trackbarName, windowName, value, count, onChange) → None\n",
    "- getTrackbarPos(trackbarName, windowName) → retval\n",
    "- imshow(name, image) → None\n",
    "- namedWindow(name, flags=CV_WINDOW_AUTOSIZE) → None\n",
    "- destroyWindow(name) → None\n",
    "- destroyAllWindows() → None\n",
    "- MoveWindow(name, x, y) → None\n",
    "- ResizeWindow(name, width, height) → None\n",
    "- SetMouseCallback(windowName, onMouse, param=None) → None\n",
    "- setTrackbarPos(trackbarName, windowName, pos) → None\n",
    "- waitKey(delay=0)  ->The function waitKey waits for a key event infinitely (when \\texttt{delay}\\leq 0 ) or for delay milliseconds, when it is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Type:**\n",
    "\n",
    "- cv2.IMREAD_COLOR\n",
    "- cv2.IMREAD_GRAYSCALE\n",
    "\n",
    "**Convert Type:**\n",
    "\n",
    "- cv2.COLOR_BGR2GRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "pic_dir=os.listdir('pic')\n",
    "print(pic_dir)\n",
    "pic_list=[]\n",
    "for a in pic_dir:\n",
    "    pic=cv2.imread('pic/'+str(a),cv2.IMREAD_COLOR)   #Read Image\n",
    "    pic_list.append(pic)\n",
    "    #cv2.namedWindow(a)\n",
    "    cv2.moveWindow(a, 0,0)  # Move it to (40,30)\n",
    "    pic=cv2.pyrDown(pic)\n",
    "    cv2.imshow(a,pic)\n",
    "    cv2.moveWindow(a, -5,0)  # Move it to (40,30)\n",
    "    key=cv2.waitKey(0) \n",
    "    key=cv2.waitKey(25)\n",
    "\n",
    "    if key==32:\n",
    "        print(key)\n",
    "        cv2.destroyWindow(a)\n",
    "    elif(key==ord('q')):\n",
    "        print(key)\n",
    "        break\n",
    "    else:\n",
    "        cv2.destroyWindow(a)\n",
    "        pass\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bacspace=8\n",
    "- tab=9\n",
    "- ecs = 27\n",
    "- space =32\n",
    "- enter =13\n",
    "- a=97,z=122\n",
    "- A=65,Z=90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "filename = 'pic/8.png'\n",
    "W = 1000.\n",
    "oriimg = cv2.imread(filename,cv2.IMREAD_COLOR)\n",
    "height, width, depth = oriimg.shape\n",
    "imgScale = W/width\n",
    "newX,newY = oriimg.shape[1]*imgScale, oriimg.shape[0]*imgScale\n",
    "newimg = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "cv2.moveWindow(\"Show by CV2\", 0,0)  # Move it to (40,30)\n",
    "cv2.imshow(\"Show by CV2\",newimg)\n",
    "cv2.waitKey(0)\n",
    "#cv2.imwrite(\"resizeimg.jpg\",newimg)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('pic/7.png',cv2.IMREAD_COLOR)\n",
    "#gray_img=cv2.imread('pic/7.png',cv2.IMREAD_GRAYSCALE)\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "new_img=cv2.resize(img,(300,300))\n",
    "cv2.imshow('window1',img)\n",
    "cv2.imshow('window2',new_img)\n",
    "cv2.imshow('window3',gray_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Canvas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('pic/7.png',cv2.IMREAD_COLOR)\n",
    "cv2.line(img,(10,10),(200,10),(0,0,255),4)\n",
    "cv2.rectangle(img,(10,20),(100,50),(255,0,0),2)\n",
    "cv2.circle(img,(250,230),100,(0,255,0),2)\n",
    "cv2.putText(img,'Sachin',(180,180),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "cv2.imshow('window1',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdo=cv2.VideoCapture('vid/bahubali.mp4')\n",
    "while(True):\n",
    "    flag,img=vdo.read()#read a frame(image) from vdo\n",
    "    img=cv2.resize(img,(600,400))\n",
    "    cv2.imshow('title',img)\n",
    "    key=cv2.waitKey(25)\n",
    "    if(key==ord('q')) or key== 32 :\n",
    "        break\n",
    "vdo.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdo=cv2.VideoCapture(0)   # 0 Default Cam\n",
    "i=1\n",
    "while(True):\n",
    "    flag,img=vdo.read()#read a frame(image) from vdo\n",
    "    img=cv2.resize(img,(600,400))\n",
    "    cv2.imwrite(f\"temp/{i}.png\",img)\n",
    "    i=i+1\n",
    "    cv2.imshow('title',img)\n",
    "    k=cv2.waitKey(25)\n",
    "    if(k==ord('q')):\n",
    "        break\n",
    "vdo.release()\n",
    "cv2.destroyAllWindows()\n",
    "#os.rmdir('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CascadeClassifier</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('pic/8.png')\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "clf=cv2.CascadeClassifier('haarcascade/haarcascade_frontalface_default.xml')\n",
    "faces=clf.detectMultiScale(gray,1.2,9)\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.imshow('',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Camera**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30, 30),flags=cv2.cv.CV_HAAR_SCALE_IMAGE)\n",
    "    faces = faceCascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30, 30))\n",
    "\n",
    "    \n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face And Eye Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img=cv2.imread('pic/1.png')\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "clf_f=cv2.CascadeClassifier('haarcascade/haarcascade_frontalface_default.xml')\n",
    "clf_e=cv2.CascadeClassifier('haarcascade/haarcascade_eye.xml')\n",
    "\n",
    "faces=clf_f.detectMultiScale(gray,1.2,9)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    fc=gray[y:y+h,x:x+h]\n",
    "    eyes=clf_e.detectMultiScale(fc)\n",
    "    for ex,ey,ew,eh in eyes:\n",
    "        cv2.rectangle(img,(x+ex,y+ey),(x+ex+ew,y+ey+eh),(255,0,0),2)\n",
    "    cv2.imshow('',img)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIC\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread('pic/7.png')\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "clf_f=cv2.CascadeClassifier('haarcascade/haarcascade_frontalface_default.xml')\n",
    "faces=clf_f.detectMultiScale(gray,1.2,9)\n",
    "for x,y,w,h in faces:\n",
    "    crop_img = img[y:y+h,x:x+w]  # fACE POSITION \n",
    "cv2.imshow(\"cropped\", crop_img)\n",
    "cv2.imwrite(\"FaceStore/crop_img.png\",crop_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n"
     ]
    }
   ],
   "source": [
    "# PIC IN dIR\n",
    "import cv2\n",
    "import os\n",
    "pic_dir=os.listdir('pic')\n",
    "print(pic_dir)\n",
    "\n",
    "clf_f=cv2.CascadeClassifier('haarcascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "pic_list=[]\n",
    "for a in pic_dir:\n",
    "    pic=cv2.imread('pic/'+str(a),cv2.IMREAD_COLOR)   #Read Image\n",
    "    pic_list.append(pic)\n",
    "    \n",
    "    gray=cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)\n",
    "    faces=clf_f.detectMultiScale(gray,1.2,9)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        crop_img = pic[y:y+h,x:x+w]  # fACE POSITION \n",
    "    cv2.imshow(\"cropped\", crop_img)\n",
    "    cv2.imwrite(\"FaceStore/crop_img\"+a,crop_img)\n",
    "    cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pic_dir=os.listdir('pic')\n",
    "clf_f=cv2.CascadeClassifier('haarcascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "pic_list=[]\n",
    "for a in pic_dir:\n",
    "    pic=cv2.imread('pic/'+str(a),cv2.IMREAD_COLOR)   #Read Image\n",
    "    pic_list.append(pic)\n",
    "    \n",
    "    gray=cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)\n",
    "    faces=clf_f.detectMultiScale(gray,1.2,9)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        crop_img = pic[y:y+h,x:x+w]  # fACE POSITION \n",
    "        \n",
    "    crop_img = cv2.resize(crop_img , (500, 500))\n",
    "    cv2.imshow(\"cropped\", crop_img)\n",
    "    cv2.imwrite(\"FaceStore/crop_img\"+a,crop_img)\n",
    "    cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame Of Image in PerSec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 30\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 10)\n",
    "fps = int(cap.get(5))\n",
    "print(\"fps:\", fps)\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('frame', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 32:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haarcascade Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('pic/8.png')\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "clf=cv2.CascadeClassifier('haarcascade/own/myhaar.xml')\n",
    "faces=clf.detectMultiScale(gray,1.2,9)\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.imshow('',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"pic/1.png\")\n",
    "#crop_img = img[y:y+h, x:x+w]\n",
    "crop_img = img[200:500, 350:500]\n",
    "cv2.imshow(\"cropped\", crop_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouse Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3cf3fb0a2e61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pillow/resizeimg.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "cropping = False\n",
    " \n",
    "x_start, y_start, x_end, y_end = 0, 0, 0, 0\n",
    " \n",
    "image = cv2.imread('pic/1.png')\n",
    "oriImage = image.copy()\n",
    " \n",
    "def mouse_crop(event, x, y, flags, param):\n",
    "    # grab references to the global variables\n",
    "    global x_start, y_start, x_end, y_end, cropping\n",
    " \n",
    "    # if the left mouse button was DOWN, start RECORDING\n",
    "    # (x, y) coordinates and indicate that cropping is being\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        x_start, y_start, x_end, y_end = x, y, x, y\n",
    "        cropping = True\n",
    " \n",
    "    # Mouse is Moving\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if cropping == True:\n",
    "            x_end, y_end = x, y\n",
    " \n",
    "    # if the left mouse button was released\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # record the ending (x, y) coordinates\n",
    "        x_end, y_end = x, y\n",
    "        cropping = False # cropping is finished\n",
    " \n",
    "        refPoint = [(x_start, y_start), (x_end, y_end)]\n",
    " \n",
    "        if len(refPoint) == 2: #when two points were found\n",
    "            roi = oriImage[refPoint[0][1]:refPoint[1][1], refPoint[0][0]:refPoint[1][0]]\n",
    "            cv2.imshow(\"Cropped\", roi)\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", mouse_crop)\n",
    " \n",
    "while True:\n",
    " \n",
    "    i = image.copy()\n",
    " \n",
    "    if not cropping:\n",
    "        cv2.imshow(\"image\", image)\n",
    " \n",
    "    elif cropping:\n",
    "        cv2.rectangle(i, (x_start, y_start), (x_end, y_end), (255, 0, 0), 2)\n",
    "        cv2.imshow(\"image\", i)\n",
    "        cv2.imwrite(\"Pillow/resizeimg.jpg\",i)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 32:\n",
    "        break\n",
    " \n",
    "# close all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
