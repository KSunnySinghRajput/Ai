{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Decision Tree Classifier</center>\n",
    "Decision tree builds classification or regression models in the form of a tree structure. It breaks down a data set into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches and a leaf node represents a classification or decision. The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data.\n",
    "\n",
    "# Decision Tree:\n",
    "\n",
    "**Introduction to Decision Trees :**\n",
    "\n",
    "<p>A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.</p>\n",
    "\n",
    "<p>A decision tree is a flowchart-like structure in which each internal node represents a “test” on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.</p>\n",
    "\n",
    "Tree based learning algorithms are considered to be one of the best and mostly used supervised learning methods. Tree based methods empower predictive models with high accuracy, stability and ease of interpretation. Unlike linear models, they map non-linear relationships quite well. They are adaptable at solving any kind of problem at hand (classification or regression). Decision Tree algorithms are referred to as **CART (Classification and Regression Trees)**\n",
    "\n",
    "- Features:x1,x2,...xn\n",
    "- Target:y\n",
    "- Node:features\n",
    "- leaf:Target\n",
    "\n",
    "### Common terms used with Decision trees:\n",
    "- **Root Node:** It represents entire population or sample and this further gets divided into two or more homogeneous sets.\n",
    "- **Splitting:** It is a process of dividing a node into two or more sub-nodes.\n",
    "- **Decision Node:** When a sub-node splits into further sub-nodes, then it is called decision node.\n",
    "- **Leaf/ Terminal Node:** Nodes do not split is called Leaf or Terminal node.\n",
    "- **Pruning:** When we remove sub-nodes of a decision node, this process is called pruning. You can say opposite process of splitting.\n",
    "- **Branch / Sub-Tree:** A sub section of entire tree is called branch or sub-tree.\n",
    "- **Parent and Child Node:** A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node.\n",
    "![](img/img-DecisionTree_RandomForestClassifier/tree-para.png)\n",
    "![](img/img-DecisionTree_RandomForestClassifier/desi.jpg)\n",
    "![](img/img-DecisionTree_RandomForestClassifier/pruning.jpg)\n",
    "![](img/img-DecisionTree_RandomForestClassifier/pruning2.jpg)\n",
    "\n",
    "\n",
    "### 1. ID3 (Iterative Dichotomiser 3):\n",
    " - Entropy & Information Gain functions\n",
    "## Manual : \n",
    "**Steps in ID3:**\n",
    "\n",
    "- a. Calculate Entropy of dataset (Target)\n",
    "- b. Calculate Entropy of each Feature\n",
    "- c. Calculate information gain of each feature\n",
    "- d. Highest gain Fetaure becomes Root Node.\n",
    "- e. Repeat same steps to buid complete Tree.\n",
    " \n",
    "![](img/img-DecisionTree_RandomForestClassifier/tree.png)\n",
    "![](img/img-DecisionTree_RandomForestClassifier/ent.PNG)\n",
    "#### A. Calculate Entropy of dataset (Target)\n",
    "\n",
    "**Find out classes in dataset.**\n",
    "- Prob of Class yes:\n",
    "<p style='text-align:center'> $P_{yes} = 9/14 =  0.642  $</p>\n",
    "   \n",
    "- Prob of Class no:\n",
    "<p style='text-align:center'> $P_{no} = 5/14 = 0.358   $</p>\n",
    "\n",
    "\n",
    "\n",
    "**Entrop(Playgolf)=Entrop(yes:9,no:5)** \n",
    "<p style='text-align:center'> $(P_{yes}*log_2*P_{yes}) + (P_{no}*log_{2}P_{no}) = (0.642*(-0.63935479754)) + (0.358*(-1.4819685074))=0.409152 + 0.530544 = 0.94   $</p>\n",
    "\n",
    "\n",
    "\n",
    "#### B. Calculate Entropy of each Feature\n",
    "\n",
    "\n",
    "**B.1 Outlook:** Find out unique values:(rainy,overcast,sunny)\n",
    "\n",
    "- Entropy of Rainy: \n",
    " <p style='text-align:center'> $E_{Rainy}=3/5*log_{2}(3/5)+2/5*log_{2}(2/5)=0.971$</p>\n",
    " \n",
    "- Entropy of Overcast:   \n",
    " <p style='text-align:center'> $E_{Overcast}=4/4*log_{2}(4/4)=0$</p>\n",
    " \n",
    "- Entropy of Sunny:     \n",
    " <p style='text-align:center'> $E_{Sunny}=3/5*log_{2}(3/5)+2/5*log_{2}(2/5)=0.971$</p>\n",
    "\n",
    "- average entropy of outlook:     \n",
    " <p style='text-align:center'> $(E_{Rainy}*P_{Rainy})+(E_{Overcast}*P_{Overcast})+(E_{Sunny}*P_{Sunny}) = (0.971*5/14)+(0)+(0.971*5/14)=0.69$</p>\n",
    "\n",
    "**B.2 Temperature:** Find out unique values:(Hot,Cool,Mild)\n",
    "\n",
    "- entropy of hot:-\n",
    " <p style='text-align:center'> $E_{hot}=2/4*log_{2}(2/4)+2/4*log_{2}(2/4)=1$</p>\n",
    "\n",
    "- entropy of cool:-\n",
    " <p style='text-align:center'> $E_{cool}=3/4*log2(3/4)+1/4*log_{2}(1/4)=0.811$</p>\n",
    "\n",
    "- entropy of mild:-\n",
    "  <p style='text-align:center'> $E_{mild}=4/6*log_{2}(4/6)+2/6*log_{2}(2/6)=0.918$</p>\n",
    "\n",
    "- average entropy of temperature: \n",
    " <p style='text-align:center'> $(E_{hot}*P_{hot})+(E_{cool}*P_{cool})+(E_{mild}*P_{mild})=>(1*4/14)+(0.811*4/14)+(0.918*6/14)=0.92$</p>\n",
    "\n",
    "**B.3 Humidity:** Find out unique values:(High, Normal)\n",
    "\n",
    "- Entropy of High:     -\n",
    " <p style='text-align:center'> $E_{high}=3/7*log_{2}(3/7)+4/7*log_{2}(4/7)   =0.985$</p>\n",
    "\n",
    "- Entropy of Normal:   -\n",
    " <p style='text-align:center'> $E_{normal}=6/7*log_{2}(6/7)+1/7*log_{2}(1/7)    =0.591$</p>\n",
    "\n",
    "- average entropy of :   \n",
    " <p style='text-align:center'> $(E_{high}*P_{high})+(E_{normal}*P_{normal})=(0.98*7/14)+(0.591*7/14)  =0.79$</p>\n",
    "    \n",
    "**B.3 Windy:** Find out unique values:(True, False)\n",
    "\n",
    "- entropy of true:-\n",
    "<p style='text-align:center'> $E_{true}=3/6*log_{2}(3/6)+3/6*log_{2}(3/6)=1$</p>\n",
    "\n",
    "- entropy of false:-\n",
    "    <p style='text-align:center'> $E_{false}=6/8*log_{2}(6/8)+2/8*log_{2}(2/8)=0.811$</p>\n",
    "\n",
    "-average entropy of : \n",
    "<p style='text-align:center'> $(E_{true}*P_{true})+(E_{false}*P_{false})=(1*6/14)+(0.811*8/14)=0.892$</p>\n",
    "\n",
    "####  C. Calculate information gain of each feature\n",
    "\n",
    "![](img/img-DecisionTree_RandomForestClassifier/Gain.PNG)\n",
    "\n",
    "Information Gain of Outlook:- \n",
    "<p style='text-align:center'> $E(playgolf)-E(Outlook)=0.94-0.69=0.25$</p>\n",
    "\n",
    "Information Gain of Temperature:\n",
    "<p style='text-align:center'> $E(playgolf)-E(temperature)=0.94-0.92=0.02$</p>\n",
    "\n",
    "Information Gain of Humidity:\n",
    "<p style='text-align:center'> $E(playgolf)-E(Humidity)=0.94-0.79=0.15$</p>\n",
    "\n",
    "Information Gain of Windy:\n",
    "<p style='text-align:center'> $E(playgolf)-E(Windy)=0.94-0.892=0.048$</p>\n",
    "\n",
    "Now outlook is root node:\n",
    "- overcast is always yes\n",
    " rainy,sunny need further splitting.\n",
    " \n",
    "**Rainy:**\n",
    "- Outlook Temp Humidity Windy Play\n",
    "- Rainy   Hot  High     FALSE  No\n",
    "- Rainy   Hot  High     TRUE   No\n",
    "- Rainy   Mild High     FALSE  No\n",
    "- Rainy   Cool Normal   FALSE  Yes\n",
    "- Rainy   Mild Normal   TRUE   Yes\n",
    "\n",
    "repeat untill we get leaf....\n",
    "\n",
    " \n",
    "\n",
    "### 2. CART(Classification And Regression Tree):\n",
    "      - Gini function\n",
    "\n",
    " # <p style='text-align:center'> $Gini = 1-∑_{j}^{i=n}P_{j}^{2}$</p>\n",
    "\n",
    "**WHERE:**\n",
    "\n",
    "        - P: PROBABILITY\n",
    "        - j:(Yes,No)\n",
    "        \n",
    "![](tree.png)\n",
    "\n",
    "#### A: Calculate gini index of dataset\n",
    "<p style='text-align:center'> $Total_{Yes} = 9$</p>\n",
    "<p style='text-align:center'> $Total_{No} = 5$</p>\n",
    "<p style='text-align:center'> $Total      = 14$</p>\n",
    "\n",
    "<p style='text-align:center'> $P_{yes}=9/14=0.64  $</p>\n",
    "<p style='text-align:center'> $P_{no}=5/14=0.35   $</p>\n",
    "\n",
    "gini index of dataset:\n",
    "        <p style='text-align:center'> $1-(P_{no}^2+P_{yes}^2) =1-(0.413+0.127)=0.46   $</p>\n",
    "\n",
    "\n",
    "#### B: Calculate gini index of each feature\n",
    "\n",
    "**B.1:**calculate gini index of outlook:\n",
    "\n",
    " <p style='text-align:center'> $Gini(outlook,rainy)=     1-[(2/5)^2+(3/5)^2]=0.48$</p>\n",
    " <p style='text-align:center'> $Gini(outlook,overcast)=  1-[(4/4)^2] = 0.0$</p>\n",
    " <p style='text-align:center'> $Gini(outlook,sunny)=     1-[(3/5)^2+(2/5)^2] =0.48$</p>\n",
    "\n",
    " <p style='text-align:center'> $Gini index of Outlook=G(o,rainy)*P_{rainy}+G(o,overcast)*P_{overcast}+G(o,sunny)*P_{sunny}\n",
    "\t=0.48*(5/14)+0+.48*(5/14)\n",
    "\t=.3428$</p>\n",
    "\n",
    "**B.2:calculate gini index of temp:**\n",
    "\n",
    " <p style='text-align:center'> $Gini(temp,hot)=1-[(2/4)^2+(2/4)^2]=1-[.25+.25]=1-.50=.50$</p>\n",
    " <p style='text-align:center'> $Gini(temp,mild)=1-[(4/6)^2+(2/6)^2]=1-[.43+.10]=.47$</p>\n",
    " <p style='text-align:center'> $Gini(temp,cold)=1-[(3/4)^2+(1/4)^2]=1-[.56+.06]=1-.62=.38$</p>\n",
    "\n",
    "<p style='text-align:center'> $Gini index of Temp=G(temp,hot)*P_{hot}+G(temp,mild)*P_{mild}+G(temp,cold)*P_{cold}\n",
    "\t=.50*(4/14)+.47*(6/14)+.38*(4/14)\n",
    "\t=.14+.20+.10\n",
    "\t=.44$</p>\n",
    "    \n",
    "**B.3:calculate gini index of Humidity:**\n",
    "\n",
    " <p style='text-align:center'> $Gini(h,high)=1-[(3/7)^2+(4/7)^2]\n",
    "\t    =1-[.17+.32]=1-.49=.51$</p>\n",
    " <p style='text-align:center'> $Gini(h,normal)=1-[(6/7)^2+(1/7)^2]\n",
    "\t      =1-[.72+.01]=1-.73=.27$</p>\n",
    "\n",
    " <p style='text-align:center'> $Gini index of Humidity=G(h,high)*P_{high}+G(h,normal)*P_{normal}\n",
    "\t=.51*(7/14)+.27*(7/14)\n",
    "\t=.25+.13\n",
    "\t=.38$</p>\n",
    "\n",
    "**B.4:calculate gini index of Windy:**\n",
    "\n",
    " <p style='text-align:center'> $Gini(windy,true)=1-[(3/6)^2+(3/6)^2]=1-[.5+.5]=1-1=0$</p>\n",
    " <p style='text-align:center'> $Gini(windy,false)=1-[(6/8)^2+(2/8)^2]=1-[.56+.06]=.62$</p>\n",
    "\t\n",
    " <p style='text-align:center'> $Gini index of Windy=G(windy,true)*P_{true}+G(windy,false)*P_{false}\n",
    "\t\t=0+.62*(8/14)\n",
    "\t\t=.35$</p>\n",
    "\n",
    "#### C: Calcilate gini gain of each feature\n",
    "\n",
    " <p style='text-align:center'> $Gini gain of Outlook=Gini(total)-Gini(Outllok)=.46-.34=.12$</p>\n",
    " <p style='text-align:center'> $Gini gain of Temp=Gini(total)-Gini(temp)=.46-.44=.02$</p>\n",
    " <p style='text-align:center'> $Gini gain of Humidity=Gini(total)-Gini(h)=.46-.38=.08$</p>\n",
    " <p style='text-align:center'> $Gini gain of Windy=Gini(total)-Gini(windy)=.46-.35=.11$</p>\n",
    " <p style='text-align:center'> $Gini gain of Humidity= .08$</p>\n",
    "\n",
    "#### D:  Pick the highest gain feature as root\n",
    "\n",
    "So Max Gini gain attribute is Outlook,make it root node\n",
    "Repeat this process for building tree.\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "\n",
    "#### E: Repeat this for further subsets to complete tree\n",
    "\n",
    "## Decision Tree Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#sklearn.__version__    #'0.21.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Outlook  Temp Humidity  Windy Play\n",
       "0   Rainy   Hot     High  False   No\n",
       "1   Rainy   Hot     High   True   No\n",
       "2   Rainy  Mild     High  False   No\n",
       "3   Rainy  Cool   Normal  False  Yes\n",
       "4   Rainy  Mild   Normal   True  Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('B:/dataset/weather_tree.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Windy</th>\n",
       "      <th>Outlook_Overcast</th>\n",
       "      <th>Outlook_Rainy</th>\n",
       "      <th>Outlook_Sunny</th>\n",
       "      <th>Temp_Cool</th>\n",
       "      <th>Temp_Hot</th>\n",
       "      <th>Temp_Mild</th>\n",
       "      <th>Humidity_High</th>\n",
       "      <th>Humidity_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Windy  Outlook_Overcast  Outlook_Rainy  Outlook_Sunny  Temp_Cool  Temp_Hot  \\\n",
       "0  False                 0              1              0          0         1   \n",
       "1   True                 0              1              0          0         1   \n",
       "2  False                 0              1              0          0         0   \n",
       "3  False                 0              1              0          1         0   \n",
       "4   True                 0              1              0          0         0   \n",
       "\n",
       "   Temp_Mild  Humidity_High  Humidity_Normal  \n",
       "0          0              1                0  \n",
       "1          0              1                0  \n",
       "2          1              1                0  \n",
       "3          0              0                1  \n",
       "4          1              0                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,:-1]   #2d\n",
    "X_new=pd.get_dummies(X)\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=X_new.values  \n",
    "Y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tree_p.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(criterion='entropy')\n",
    "dtree.fit(X_new,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=dtree.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
