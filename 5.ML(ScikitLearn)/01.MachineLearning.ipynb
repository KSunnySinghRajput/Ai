{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJelX_lmhn8U"
   },
   "source": [
    "# <center>Machine Learning</center>\n",
    "![](_pic/img-ML/Ml.jpg)\n",
    "(ML) is the scientific study of algorithms and statistical models that computer systems use in order to perform a specific task effectively without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence</p>\n",
    "\n",
    "Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task\n",
    " \n",
    "**Need for Machine Learning**<br>\n",
    "Human beings, at this moment, are the most intelligent and advanced species on earth because they can think, evaluate and solve complex problems. On the other side, AI is still in its initial stage and haven’t surpassed human intelligence in many aspects. Then the question is that what is the need to make machine learn? The most suitable reason for doing this is, “to make decisions, based on data, with efficiency and scale”.\n",
    "\n",
    "Lately, organizations are investing heavily in newer technologies like Artificial Intelligence, Machine Learning and Deep Learning to get the key information from data to perform several real-world tasks and solve problems. We can call it data-driven decisions taken by machines, particularly to automate the process. These data-driven decisions can be used, instead of using programing logic, in the problems that cannot be programmed inherently. The fact is that we can’t do without human intelligence, but other aspect is that we all need to solve real-world problems with efficiency at a huge scale. That is why the need for machine learning arises.\n",
    "\n",
    "**Challenges in Machines Learning**<br>\n",
    "While Machine Learning is rapidly evolving, making significant strides with cybersecurity and autonomous cars, this segment of AI as whole still has a long way to go. The reason behind is that ML has not been able to overcome number of challenges. The challenges that ML is facing currently are −\n",
    "\n",
    "   - **Quality of data** − Having good-quality data for ML algorithms is one of the biggest challenges. Use of low-quality data leads to the problems related to data preprocessing and feature extraction.\n",
    "\n",
    "   - **Time-Consuming task** - Another challenge faced by ML models is the consumption of time especially for data acquisition, feature extraction and retrieval.\n",
    "\n",
    "   - **Lack of specialist persons** − As ML technology is still in its infancy stage, availability of expert resources is a tough job.\n",
    "\n",
    "   - **No clear objective for formulating business problems** − Having no clear objective and well-defined goal for business problems is another key challenge for ML because this technology is not that mature yet.\n",
    "\n",
    "   - **Issue of overfitting & underfitting** − If the model is overfitting or underfitting, it cannot be represented well for the problem.\n",
    "\n",
    "   - **Curse of dimensionality** − Another challenge ML model faces is too many features of data points. This can be a real hindrance.\n",
    "\n",
    "   - **Difficulty in deployment** − Complexity of the ML model makes it quite difficult to be deployed in real life.\n",
    "    \n",
    "**Application of Machine learning**<br>\n",
    "Agriculture, Anatomy, Adaptive websites, Affective computing, Banking, Bioinformatics, Brain–machine interfaces,      Cheminformatics, Computer Networks, Computer vision, Credit-card fraud detection, Data quality, DNA sequence classification Economics, Financial market analysis, General game playing, Handwriting recognition, Information retrieval, Insurance, Internet fraud detection, Linguistics, Machine learning control, Machine perception, Machine translation, Marketing, Medical diagnosis, Natural language processing, Natural language understanding, Online advertising, Optimization, Recommender systems, Robot locomotion, Search engines, Sentiment analysis, Sequence mining, Software engineering, Speech recognition, Structural health monitoring, Syntactic pattern recognition, Telecommunication, Theorem proving, Time series forecasting, User behavior analytics\n",
    "\n",
    "**Machine Learning Model**<br>\n",
    "Based on the above, the following diagram represents a Machine Learning Model −\n",
    "![](_img/img-ML/machine_learning_model.jpg)\n",
    "Before discussing the machine learning model, we must need to understand the following formal definition of ML given by professor Mitchell −\n",
    "\n",
    "“A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”\n",
    "\n",
    "The above definition is basically focusing on three parameters, also the main components of any learning algorithm, namely Task(T), Performance(P) and experience (E).\n",
    "\n",
    "ML is a field of AI consisting of learning algorithms that −\n",
    "  - Improve their performance (P)\n",
    "  - At executing some task (T)\n",
    "  - Over time with experience (E)\n",
    "\n",
    "\n",
    "Let us discuss them more in detail now −\n",
    "\n",
    "1. **Task(T)**<br>\n",
    "From the perspective of problem, we may define the task T as the real-world problem to be solved. The problem can be anything like finding best house price in a specific location or to find best marketing strategy etc. On the other hand, if we talk about machine learning, the definition of task is different because it is difficult to solve ML based tasks by conventional programming approach.\n",
    "A task T is said to be a ML based task when it is based on the process and the system must follow for operating on data points. The examples of ML based tasks are Classification, Regression, Structured annotation, Clustering, Transcription etc.\n",
    "\n",
    "2. **Experience (E)**<br>\n",
    "As name suggests, it is the knowledge gained from data points provided to the algorithm or model. Once provided with the dataset, the model will run iteratively and will learn some inherent pattern. The learning thus acquired is called experience(E). Making an analogy with human learning, we can think of this situation as in which a human being is learning or gaining some experience from various attributes like situation, relationships etc. Supervised, unsupervised and reinforcement learning are some ways to learn or gain experience. The experience gained by out ML model or algorithm will be used to solve the task T.\n",
    "\n",
    "3. **Performance (P)**<br>\n",
    "An ML algorithm is supposed to perform task and gain experience with the passage of time. The measure which tells whether ML algorithm is performing as per expectation or not is its performance (P). P is basically a quantitative metric that tells how a model is performing the task, T, using its experience, E. There are many metrics that help to understand the ML performance, such as accuracy score, F1 score, confusion matrix, precision, recall, sensitivity etc.\n",
    "\n",
    "\n",
    "\n",
    "**Terms Used in machine Learning:**\n",
    "- Input/Features/Attributes/Dimensions refer to parameters (columns) of training dataset.\n",
    "- Instance represents one sample of training dataset.\n",
    "- Label/class/target refers output of training dataset.\n",
    "- X is symbol for features and y is symbol for label\n",
    "Example:\n",
    "<table border=\"1\">  \n",
    "<tr><th>Age</th><th>Salary</th><th>Purchased</th></tr>  \n",
    "<tr><td>44 </td><td>72000</td><td> No</td></tr> \n",
    "<tr><td>27</td><td> 48000</td><td> Yes</td></tr> \n",
    "<tr><td>30 </td><td>54000</td><td> No</td></tr> \n",
    "<tr><td>38 </td><td>61000</td><td> No</td></tr> \n",
    "<tr><td>40 </td><td>40000</td><td> Yes</td></tr> \n",
    "<tr><td>35 </td><td>58000</td><td> Yes</td></tr> \n",
    "<tr><td>42 </td><td>52000</td><td> No</td></tr> \n",
    "<tr><td>48 </td><td>79000</td><td> Yes</td></tr> \n",
    "<tr><td>50 </td><td>83000</td><td> No</td></tr> \n",
    "<tr><td>37 </td><td>67000</td><td> Yes</td></tr> \n",
    "</table>  \n",
    "\n",
    "Here, Age and Salary are features(X) and Purchased is Label(y) and 44,72000 is\n",
    "one instance of features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "source": [
    "### ML Process\n",
    "![](_pic/img-ML/MLProcess.png)\n",
    "\n",
    "![](_pic/img-ML/Steps-to-Predictive-Modelling.jpg)\n",
    "\n",
    "    Step 1 − First, we need to collect all the training data for start training the model.\n",
    "    Step 2 − Now, start the training of model by providing whole training data in one go.\n",
    "    Step 3 − Next, stop learning/training process once you got satisfactory results/performance.\n",
    "    Step 4 − Finally, deploy this trained model into production. Here, it will predict the output for new data sample.\n",
    "\n",
    "**Python Implementation of ML:**\n",
    "There are following two popular ML libraries in python:\n",
    " 1. Scikit-learn\n",
    " 2. Tensor flow (aka deep learning)\n",
    "\n",
    "**Scikit-learn:**\n",
    "<center>cmd-> pip install scikit-learn</center>\n",
    "\n",
    "- It was developed by Google in 2007 and publically available from 2010 as open source library.\n",
    "- You can download Scikit learn by writing following command\n",
    "\n",
    "If you are using anaconda IDE, it is by default bundled.\n",
    "\n",
    "- NOTE 1: This library takes features in numeric form so we must convert all features into numbers before passing data to training.\n",
    "\n",
    "- NOTE 2: After converting features into numbers we must represents these features in 2d array or nested list. In the same way label must be represented as 1d array or list.\n",
    "\n",
    "#### Example:-\n",
    "\n",
    "Consider following dataset of online purchased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "source": [
    "<table border=\"1\">  \n",
    "<tr><th>Age</th><th>Salary</th><th>Purchased</th></tr>  \n",
    "<tr><td>44 </td><td>72000</td><td> No</td></tr> \n",
    "<tr><td>27</td><td> 48000</td><td> Yes</td></tr> \n",
    "<tr><td>30 </td><td>54000</td><td> No</td></tr> \n",
    "<tr><td>38 </td><td>61000</td><td> No</td></tr> \n",
    "<tr><td>40 </td><td>40000</td><td> Yes</td></tr> \n",
    "<tr><td>35 </td><td>58000</td><td> Yes</td></tr> \n",
    "<tr><td>42 </td><td>52000</td><td> No</td></tr> \n",
    "<tr><td>48 </td><td>79000</td><td> Yes</td></tr> \n",
    "<tr><td>50 </td><td>83000</td><td> No</td></tr> \n",
    "<tr><td>37 </td><td>67000</td><td> Yes</td></tr> \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "source": [
    "By observing above dataset we may conclude that given example belongs to classification problem of supervise learning.\n",
    "- Features: Age, Salary\n",
    "- Label or Target: Purchased\n",
    "\n",
    "Now,Represents these features as 2d array and label as 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "outputs": [],
   "source": [
    "data=[[44,72000], [27,48000],[30,540000], [38,61000], [40,40000], [35,58000],[42,52000], [48,79000], [50,83000], [37,67000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "outputs": [],
   "source": [
    "label=[0,1,0,0,1,1,0,1,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "source": [
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(data,label)\n",
    "knn.predict([[32,20000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lByFHH8hn9l"
   },
   "source": [
    "**NOTE:**\n",
    "- Most of the times we do not have cleaned or prepared dataset so we must prepare dataset before passing it to training.\n",
    "\n",
    "**Data Preprocessing:**\n",
    "- Identify missing values in features\n",
    "- Fill these missing values by using mean or other approach\n",
    "- You may also drop a row if most of the values are missing\n",
    "- Sometimes not all features are required in training ,remove those features\n",
    "- Converting features and label into numeric values so that dataset can be passed to training.\n",
    "- Do feature Scaling if values of features are not in same range.\n",
    "\n",
    "## <a href=\"b.TrainAndTest.ipynb\">Hint:Feature Selection Train Test </a>\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inkZC41ohn9r"
   },
   "source": [
    "### Types of Learning algorithms\n",
    "\n",
    "![](_pic/img-ML/tyMl.jpg)\n",
    "\n",
    "The following are various ML methods based on some broad categories −"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Supervised Learning\n",
    "\n",
    "- <p>Supervised learning algorithms or methods are the most commonly used ML algorithms. This method or learning algorithm take the data sample i.e. the training data and its associated output i.e. labels or responses with each data samples during the training process.</p>\n",
    "\n",
    "- <p>These are the algorithms that work on predictions and search for patterns on given set of samples. Supervised Machine Learning Algorithms attempt to render relationships and dependencies between the target prediction output and the input features. In this, we start from input variables (x) and an output variable (Y) and try to map functions from the input to the output so that they establish a relationship which can be used for prediction.</p>\n",
    "\n",
    "- The main objective of supervised learning algorithms is to learn an association between input data samples and corresponding outputs after performing multiple training data instances.\n",
    "\n",
    "For example, we have\n",
    "\n",
    "**X(Feature)** − Input variables and\n",
    "\n",
    "**Y(Target)** − Output variable(labeled data)\n",
    "\n",
    "Now, apply an algorithm to learn the mapping function from the input to output as follows −\n",
    "\n",
    "**Y=f(x)**<BR>\n",
    "Now, the main objective would be to approximate the mapping function so well that even when we have new input data (x), we can easily predict the output variable (Y) for that new input data.\n",
    "\n",
    "![](img/img-SupervisedLearning/S.png)\n",
    "\n",
    "**Based on the ML tasks, supervised learning algorithms can be divided into following two broad classes :-**\n",
    "\n",
    "#### 1.Regression\n",
    "\n",
    "The key objective of regression-based tasks is to predict output labels or responses which are continues numeric values, for the given input data. The output will be based on what the model has learned in its training phase. Basically, regression models use the input data features (independent variables) and their corresponding continuous numeric output values (dependent or outcome variables) to learn specific association between inputs and corresponding outputs. We will discuss regression and associated algorithms in detail in further chapters also.\n",
    "\n",
    "**Algo**\n",
    "\n",
    "1. <a href=\"02.LinearRegression.ipynb\">Linear Regression</a>\n",
    "2. <a href=\"03.MultipleRegression.ipynb\">Multiple Regression</a>\n",
    "3. <a href=\"04.PolynomialRegression.ipynb\">Polynomial Regression </a>\n",
    "\n",
    "\n",
    "####  2.Classification\n",
    "\n",
    "The key objective of classification-based tasks is to predict categorial output labels or responses for the given input data. The output will be based on what the model has learned in training phase. As we know that the categorial output responses means unordered and discrete values, hence each output response will belong to a specific class or category. We will discuss Classification and associated algorithms in detail in the upcoming chapters also.\n",
    "- In machine learning and statistics, classification is a supervised learning approach in which the computer program learns from the data input given to it and then uses this learning to classify new observation. This data set may simply be bi-class (like identifying whether the person is male or female or that the mail is spam or non-spam) or it may be multi-class too. Some examples of classification problems are: speech recognition, handwriting recognition, bio metric identification, document classification etc.\n",
    "\n",
    "- A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”. A classification model attempts to draw some conclusion from observed values. Given one or more inputs a classification model will try to predict the value of one or more outcomes.\n",
    "\n",
    "**Which of the following is/are classification problem(s)**\n",
    "\n",
    "- Predicting the gender of a person by his/her handwriting style\n",
    "- Predicting house price based on area\n",
    "- Predicting whether monsoon will be normal next year\n",
    "- Predict the number of copies a music album will be sold next month\n",
    "- For example, when filtering emails “spam” or “not spam”, when looking at transaction data, “fraudulent”, or “authorized”. In short Classification either predicts categorical class labels or classifies data (construct a model) based on the training set and the values (class labels) in classifying attributes and uses it in classifying new data. \n",
    "- Predicting whether monsoon will be normal next year. The other two are regression. As we discussed classification with some examples. Now there is an example of classification in which we are performing classification on the iris dataset using RandomForestClassifier in python. You can download the dataset from Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***Algo***\n",
    "\n",
    "- Here we have the types of classification algorithms in Machine Learning:\n",
    "    1. <a href=\"05.LogisticRegression.ipynb\">Logistic Regression</a>\n",
    "    2. <a href=\"06.NaiveBayes.ipynb\">Naive Bayes Classifier</a>\n",
    "    3. <a href=\"07.DecisionTree.ipynb\">Decision trees </a>\n",
    "    4. <a href=\"08.RandomForestClassifier.ipynb\">Random Forest</a>\n",
    "    5. <a href=\"09.BoostedTree.ipynb\">Gradient-Boosted Tree (Boosted Trees)</a>\n",
    "    6. <a href=\"10.KNearestNeighbor.ipynb\">K Nearest Neighbor(KNN)</a>\n",
    "    7. <a href=\"11.SupportVectorMachines.ipynb\">Support Vector Machines(SVM)</a>\n",
    "    8.  Multilayer Perceptron\n",
    "    9.  One Vs Rest\n",
    "    10. Neural Networks\n",
    "        - Neural Networks (Multilayer perceptron)\n",
    "\n",
    "**Note:-Linear Classifiers: Logistic Regression, Naive Bayes Classifier**\n",
    "   - **Dimensionality Reduction**\n",
    "    - PCA (Principal Component Analysis)\n",
    "    - Discriminant analysis\n",
    "\n",
    "    - linear discriminant analysis\n",
    "    - Similarity learning\n",
    "\n",
    "**Neural Network:**\n",
    "<p>A neural network consists of units (neurons), arranged in layers, which convert an input vector into some output. Each unit takes an input, applies a (often nonlinear) function to it and then passes the output on to the next layer. Generally the networks are defined to be feed-forward: a unit feeds its output to all the units on the next layer, but there is no feedback to the previous layer. Weightings are applied to the signals passing from one unit to another, and it is these weightings which are tuned in the training phase to adapt a neural network to the particular problem at hand.\n",
    "Machine Learning</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Unsupervised Learning\n",
    "\n",
    "- Unsupervised learning algorithms take a set of data that contains only inputs, and find structure in the data, like grouping or clustering of data points. The algorithms therefore learn from test data that has not been labeled, classified or categorized.\n",
    "\n",
    "- Unsupervised learning takes place when you have no labelled data available for training. It is the basic type algorithm where you only have input data and no coinciding output variables. These are called so because there is no corresponding output to a particular input. Their problems can be further grouped into clustering to discover inherent grouping and association problems.\n",
    "\n",
    "- Examples of unsupervised machine learning algorithms includes K-means clustering, K-nearest neighbors etc.\n",
    "For example, it can be understood as follows −\n",
    "\n",
    "![](img/img-ML/uns.png)\n",
    "Suppose we have,\n",
    "- **x** −Input variables, then there would be no corresponding output variable and the algorithms need to discover the interesting pattern in data for learning.\n",
    "- **Target** : unlabeled data.\n",
    "\n",
    "Based on the ML tasks, unsupervised learning algorithms can be divided into following broad classes −\n",
    "\n",
    "### a. Clustering\n",
    "Clustering methods are one of the most useful unsupervised ML methods. These algorithms used to find similarity as well as relationship patterns among data samples and then cluster those samples into groups having similarity based on features. The real-world example of clustering is to group the customers by their purchasing behavior.\n",
    "\n",
    "### b. Association\n",
    "Another useful unsupervised ML method is Association which is used to analyze large dataset to find patterns which further represents the interesting relationships between various items. It is also termed as Association Rule Mining or Market basket analysis which is mainly used to analyze customer shopping patterns.\n",
    "\n",
    "### c. Dimensionality Reduction\n",
    "This unsupervised ML method is used to reduce the number of feature variables for each data sample by selecting set of principal or representative features. A question arises here is that why we need to reduce the dimensionality? The reason behind is the problem of feature space complexity which arises when we start analyzing and extracting millions of features from data samples. This problem generally refers to “curse of dimensionality”. PCA (Principal Component Analysis), K-nearest neighbors and discriminant analysis are some of the popular algorithms for this purpose.\n",
    "\n",
    "**Algorithms:**\n",
    "\n",
    "The most widely used learning algorithms are:\n",
    "\n",
    "- **Clustering**\n",
    "    - <a href=\"12.KMean.ipynb\">K-means clustering(imp)</a>\n",
    "    - Mean-Shift Algorithm\n",
    "    - Hierarchical Clustering\n",
    "\n",
    "- **Dimensionality Reduction**\n",
    "    - PCA (Principal Component Analysis)\n",
    "    - Discriminant analysis\n",
    "    - K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Semi-Supervise Learning\n",
    "Combination of supervise and unsupervised learning, means in sample\n",
    "dataset some features are given with their labels and some features are given without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Reinforcement Learning:\n",
    "\n",
    "These algorithms forward an action according to the data point and later assess the decision. Algorithm utilises the observations collected from the interaction and take actions so as to minimise the risk and maximise the benefits. The algorithm learns in an iterative fashion. Common Algorithms that come under the reinforcement are Q-Learning, Deep Adversarial Networks, and Temporal Difference. Algorithm is applicable in the field of Game AI, skill acquisition, learning tasks, robot navigation and real-time decision.\n",
    "\n",
    "- No features and labels are given initially\n",
    "- Reward or feedback is given to an action, positive or negative moves become experience.\n",
    "\n",
    "**Move** ->becomes features.\n",
    "\n",
    "**Reward/feedback**->become label\n",
    "\n",
    "Example: chess game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "# <center><u>Important Topic</u></center>\n",
    "#  A)  Feature Preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.array([[ 1., -1.,  2.],\n",
    "                     [ 2.,  0.,  0.],\n",
    "                     [ 0.,  1., -1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.scale(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **\"fit\"** computes the mean and std to be used for later scaling. (jsut a computation), nothing is given to you. \n",
    "\n",
    "- **\"transform\"** uses a previously computed mean and std to autoscale the data (subtract mean from all values and then divide it by std).\n",
    "- **\"fit_transform\"** does both at the same time.\n",
    "\n",
    "**Scaling features to a range**\n",
    "\n",
    "- MinMaxScaler \n",
    "- MaxAbsScaler\n",
    "\n",
    "**Load Dataset/Clean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "### 2. MinMaxScalar :\n",
    " <center>$\\begin{align*}MinRange+(MaxRange-MinRange)*(x_i-x_min)/(xmax-xmin)\\end{align*}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "#sc=MinMaxScaler(feature_range=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81649658, 0.81649658, 1.24721913])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StandardScaler' object has no attribute 'min_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-14a5edd69556>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'StandardScaler' object has no attribute 'min_'"
     ]
    }
   ],
   "source": [
    "sc.min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "### 2. MaxAbsScaler :\n",
    " ## <center>$\\begin{align*}\\frac{x_i}{abs(x_{max})}\\end{align*}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  2.],\n",
       "       [ 2.,  0.,  0.],\n",
       "       [ 0.,  1., -1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5, -1. ,  1. ],\n",
       "       [ 1. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. , -0.5]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc=preprocessing.MaxAbsScaler()\n",
    "sc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "### 3. Standard Scalar :\n",
    " ## <center>$\\begin{align*}\\frac{x_i-x_{mean}}{std\\ of\\ feature}\\end{align*}$</center>\n",
    " \n",
    "  **full formula is:**\n",
    " \n",
    " \n",
    "**X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))**\n",
    "\n",
    "**X_scaled = X_std * (max - min) + min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  2.],\n",
       "       [ 2.,  0.,  0.],\n",
       "       [ 0.,  1., -1.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A=np.array([1,0,2,2,1])\n",
    "std=np.std(A)\n",
    "mean=np.mean(A)\n",
    "(1-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc=preprocessing.StandardScaler()\n",
    "sc.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "### 4. Normalizer :\n",
    "\n",
    "**it works with row **\n",
    "\n",
    "## <center>$\\begin{align*}\\frac{x_i}{(sum\\ of\\ square\\ each\\ element\\ in\\ row)^{2}}\\end{align*}$</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "### 5. Binarizer :\n",
    "all values above threshold will be 1 and less or same will be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "## B. [Train And Test](b.TrainAndTest.ipynb)\n",
    "- Dataset Selection for Train And Test\n",
    "    -  train_test_split\n",
    "    -  Cross-Validated metrics\n",
    "    -  K-Fold\n",
    "    -  ShuffleSplit\n",
    "- Train And Test Problem:\n",
    "    - Fitting Problem \n",
    "    - Type of Fitting (Under Fitting and Over Fitting)\n",
    "    - The Bias vs Variance trade-off\n",
    "    - Regularization\n",
    "    - Variance\n",
    "    - Ideal Statement for a Model\n",
    "\n",
    "<a href=\"b.TrainAndTest.ipynb\">more....</a>\n",
    "\n",
    "### C) Feature Extraction\n",
    "    - It is a technique to extract features from a corpus(in text) or images.\n",
    "    - In Text classification we need to extract feature from a corpus and in image classificaion we need to extract feature from images.\n",
    "- <a href=\"c.i.FeatureExtractionInText.ipynb\">Feature Extraction in Text</a>\n",
    "- <a href=\"c.ii.FeatureExtractionInImage.ipynb\">Feature Extraction in Image</a>\n",
    "\n",
    "\n",
    "### <a href=\"d.ParameterTuning.ipynb\">D) Parameter Tuning</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCs6_IEDhn9y"
   },
   "source": [
    "# <center>Performance Metrics(Parameters) for classification:</u></center>\n",
    "\n",
    "## 1. [Confusion Matrix](e.ConfusionMatrix.ipynb)\n",
    "\n",
    "![](_pic/img-performance/ConfusionMatrics.png)\n",
    "\n",
    "**Terms associated with Confusion matrix:**\n",
    "\n",
    "**1. True Positives (TP):** \n",
    "\n",
    "- True positives are the cases when the actual class of the data point was 1(True) and the predicted is also 1(True)\n",
    "\n",
    "**2. True Negatives (TN):** \n",
    "\n",
    "- True negatives are the cases when the actual class of the data point was 0(False) and the predicted is also 0(False)\n",
    "\n",
    "**3. False Positives (FP):**\n",
    "\n",
    "- False positives are the cases when the actual class of the data point was 0(False) and the predicted is 1(True). False is because the model has predicted incorrectly and positive because the class predicted was a positive one. (1)\n",
    "\n",
    "**4. False Negatives (FN):** \n",
    "\n",
    "- False negatives are the cases when the actual class of the data point was 1(True) and the predicted is 0(False). False is because the model has predicted incorrectly and negative because the class predicted was a negative one. (0) \n",
    "\n",
    "**Accuracy** measures how well the test predicts both True and Negative classes.\n",
    "(Overall correctness of model) \n",
    "\n",
    "<center>$\\begin{align*}Accuracy = \\frac{TP +TN}{TP + FP + FN + TN}\\end{align*}$</center>\n",
    "\n",
    "\n",
    "**Sensitivity (Recall or True positive rate)** measures the proportion of positives that are correctly identified as such \n",
    "(Accuracy of class 1)\n",
    "\n",
    " <center>$\\begin{align*}Recall =\\frac{TP }{TP + FN}\\end{align*}$</center>\n",
    "\n",
    "\n",
    "**Specificity (True negative rate)** measures the proportion of negatives that are correctly identified as such. \n",
    "(Accuracy of class 0)\n",
    "\n",
    " <center>$\\begin{align*}Specificity = \\frac{TN}{TN + FP}\\end{align*}$</center>\n",
    " \n",
    "**Precision (Positive Predictive Value)** is intuitively the ability of the classifier not to label as positive a sample that is\n",
    "negative.\n",
    "(How Many predicted 1 are actually 1)\n",
    "\n",
    "<center>$\\begin{align*}Precision =\\frac{TP }{FP + TP}\\end{align*}$</center>\n",
    "\n",
    "**Negative Predictive Value** \n",
    "\n",
    "<center>$\\begin{align*}Negative Predictive Value =\\frac{TN}{FN + TN}\\end{align*}$</center>\n",
    "\n",
    "\n",
    "**False Positive Rate (FPR) :**\n",
    "The false positive rate is the proportion of all negatives that still yield positive test outcomes.\n",
    "\n",
    " <center>$\\begin{align*}False Positive Rate= \\frac{FP}{FP + TN}\\end{align*}$</center>\n",
    " \n",
    " \n",
    "**F-1 Score:**\n",
    "If we have immbalanced data like in titanic we have majority of sample belonging to 0 class.\n",
    "\n",
    "Or suppose consider:\n",
    "\n",
    "- 100 samples(instances)->class 0\n",
    "\n",
    "- 20 samples(instances)->class 1\n",
    "\n",
    "The above data is immbalanced.\n",
    "\n",
    "So ,with immbalanced data we should test model performance by using F-1 score.\n",
    "\n",
    "<center> $\\begin{align*}F1 = 2 *\\frac{precision * recall}{precision + recall} \\end{align*}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset/Clean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  EstimatedSalary  Purchased\n",
       "0       1   19            19000          0\n",
       "1       1   35            20000          0\n",
       "2       2   26            43000          0\n",
       "3       2   27            57000          0\n",
       "4       1   19            76000          0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('_dataset/Dataset-ConfusionMatrix/Online_Ads.csv')\n",
    "#hot encoding\n",
    "df['Gender']=df['Gender'].map({'Male':1, 'Female':2})\n",
    "X=df.loc[:,('Age','EstimatedSalary','Gender')].values\n",
    "y=df.loc[:,'Purchased'].values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing (Standard Scaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "sc=preprocessing.StandardScaler()\n",
    "X_new=sc.fit_transform(X.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model selection (Train Test Split)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_new,y,random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Train/Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log=LogisticRegression()\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=log.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn=neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "      - sklearn.metrics.confusion_matrix(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "cm=metrics.confusion_matrix(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.9\n",
      "Sensitivity = Recall = TruePositiveRate = TPR :0.9285714285714286\n",
      "Specificity :0.8888888888888888\n",
      "Precision :0.7647058823529411\n",
      "FalsePositiveRate :0.1111111111111111\n",
      "F1Score :0.8387096774193549\n"
     ]
    }
   ],
   "source": [
    "#Mannual\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "Accuracy=(tn+tp)/(tn+fp+fn+tp)\n",
    "Sensitivity = Recall = TruePositiveRate = TPR =tp/(tp+fn)\n",
    "Specificity=tn/(tn+fp)\n",
    "Precision=tp/(fp+tp)\n",
    "FalsePositiveRate= FPR = (fp/(fp + tn))\n",
    "F1Score=2*(Precision*Recall)/(Precision + Recall)\n",
    "print(\"Accuracy :\"+str(Accuracy))\n",
    "print(\"Sensitivity = Recall = TruePositiveRate = TPR :\"+str(Recall))\n",
    "print(\"Specificity :\"+str(Specificity))\n",
    "print(\"Precision :\"+str(Precision))\n",
    "print(\"FalsePositiveRate :\"+str(FalsePositiveRate))\n",
    "print(\"F1Score :\"+str(F1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387096774193549"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MachineLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
