{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sktime pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lined-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "understanding-marble",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Regions</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>NR</td>\n",
       "      <td>31.519974</td>\n",
       "      <td>75.980003</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>119.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>NR</td>\n",
       "      <td>28.450006</td>\n",
       "      <td>77.019991</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>130.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>NR</td>\n",
       "      <td>26.449999</td>\n",
       "      <td>74.639981</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>234.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>NR</td>\n",
       "      <td>28.669993</td>\n",
       "      <td>77.230004</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>313.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>NER</td>\n",
       "      <td>24.799971</td>\n",
       "      <td>93.950017</td>\n",
       "      <td>05/12/2020 00:00:00</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.570492</td>\n",
       "      <td>91.880014</td>\n",
       "      <td>05/12/2020 00:00:00</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16596</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.710399</td>\n",
       "      <td>92.720015</td>\n",
       "      <td>05/12/2020 00:00:00</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16597</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.666998</td>\n",
       "      <td>94.116570</td>\n",
       "      <td>05/12/2020 00:00:00</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16598</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.835404</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>05/12/2020 00:00:00</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16599 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          States Regions   latitude  longitude                Dates  Usage\n",
       "0         Punjab      NR  31.519974  75.980003  02/01/2019 00:00:00  119.9\n",
       "1        Haryana      NR  28.450006  77.019991  02/01/2019 00:00:00  130.3\n",
       "2      Rajasthan      NR  26.449999  74.639981  02/01/2019 00:00:00  234.1\n",
       "3          Delhi      NR  28.669993  77.230004  02/01/2019 00:00:00   85.8\n",
       "4             UP      NR  27.599981  78.050006  02/01/2019 00:00:00  313.9\n",
       "...          ...     ...        ...        ...                  ...    ...\n",
       "16594    Manipur     NER  24.799971  93.950017  05/12/2020 00:00:00    2.5\n",
       "16595  Meghalaya     NER  25.570492  91.880014  05/12/2020 00:00:00    5.8\n",
       "16596    Mizoram     NER  23.710399  92.720015  05/12/2020 00:00:00    1.6\n",
       "16597   Nagaland     NER  25.666998  94.116570  05/12/2020 00:00:00    2.1\n",
       "16598    Tripura     NER  23.835404  91.279999  05/12/2020 00:00:00    3.3\n",
       "\n",
       "[16599 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"../_dataset/IndiaPowerConsumtion/long_data_.csv\"\n",
    "raw = pd.read_csv(path)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "frequent-graphics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Andhra Pradesh',\n",
       " 'Arunachal Pradesh',\n",
       " 'Assam',\n",
       " 'Bihar',\n",
       " 'Chandigarh',\n",
       " 'Chhattisgarh',\n",
       " 'DNH',\n",
       " 'Delhi',\n",
       " 'Goa',\n",
       " 'Gujarat',\n",
       " 'HP',\n",
       " 'Haryana',\n",
       " 'J&K',\n",
       " 'Jharkhand',\n",
       " 'Karnataka',\n",
       " 'Kerala',\n",
       " 'MP',\n",
       " 'Maharashtra',\n",
       " 'Manipur',\n",
       " 'Meghalaya',\n",
       " 'Mizoram',\n",
       " 'Nagaland',\n",
       " 'Odisha',\n",
       " 'Pondy',\n",
       " 'Punjab',\n",
       " 'Rajasthan',\n",
       " 'Sikkim',\n",
       " 'Tamil Nadu',\n",
       " 'Telangana',\n",
       " 'Tripura',\n",
       " 'UP',\n",
       " 'Uttarakhand',\n",
       " 'West Bengal'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(raw.States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "plastic-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Regions</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>313.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>03/01/2019 00:00:00</td>\n",
       "      <td>311.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>04/01/2019 00:00:00</td>\n",
       "      <td>320.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>05/01/2019 00:00:00</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>06/01/2019 00:00:00</td>\n",
       "      <td>286.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16438</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>01/12/2020 00:00:00</td>\n",
       "      <td>322.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16471</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>02/12/2020 00:00:00</td>\n",
       "      <td>331.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16504</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>03/12/2020 00:00:00</td>\n",
       "      <td>336.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16537</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>04/12/2020 00:00:00</td>\n",
       "      <td>334.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16570</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>05/12/2020 00:00:00</td>\n",
       "      <td>287.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      States Regions   latitude  longitude                Dates  Usage\n",
       "4         UP      NR  27.599981  78.050006  02/01/2019 00:00:00  313.9\n",
       "37        UP      NR  27.599981  78.050006  03/01/2019 00:00:00  311.8\n",
       "70        UP      NR  27.599981  78.050006  04/01/2019 00:00:00  320.7\n",
       "103       UP      NR  27.599981  78.050006  05/01/2019 00:00:00  299.0\n",
       "136       UP      NR  27.599981  78.050006  06/01/2019 00:00:00  286.8\n",
       "...      ...     ...        ...        ...                  ...    ...\n",
       "16438     UP      NR  27.599981  78.050006  01/12/2020 00:00:00  322.8\n",
       "16471     UP      NR  27.599981  78.050006  02/12/2020 00:00:00  331.4\n",
       "16504     UP      NR  27.599981  78.050006  03/12/2020 00:00:00  336.7\n",
       "16537     UP      NR  27.599981  78.050006  04/12/2020 00:00:00  334.6\n",
       "16570     UP      NR  27.599981  78.050006  05/12/2020 00:00:00  287.3\n",
       "\n",
       "[503 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[raw.States==\"UP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "pacific-aquatic",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['brand'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-2aca817fc926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dates'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Usage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'temp/UP_power.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'brand'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\pythonenv\\base3.7\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   5266\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"inplace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5267\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ignore_index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5268\u001b[1;33m         \u001b[0mduplicated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5270\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonenv\\base3.7\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   5400\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5402\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5404\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Index(['brand'], dtype='object')"
     ]
    }
   ],
   "source": [
    "df2=raw[['Dates','Usage']]\n",
    "df2.to_csv('temp/UP_power.csv', index = False)\n",
    "df2.drop_duplicates(subset=['brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "effective-insight",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'duplicated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-5f6754f9d628>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dates'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\pythonenv\\base3.7\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         raise AttributeError(\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[1;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'duplicated'"
     ]
    }
   ],
   "source": [
    "df.duplicated(subset=['Dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "induced-forge",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'duplicated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-a425f46e4a9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\pythonenv\\base3.7\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         raise AttributeError(\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[1;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'duplicated'"
     ]
    }
   ],
   "source": [
    "df.dates=pd.to_datetime(df2.Dates)\n",
    "df[df.dates==a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "proprietary-condition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Timestamp('2019-01-07 00:00:00'),\n",
       " Timestamp('2019-01-08 00:00:00'),\n",
       " Timestamp('2019-01-09 00:00:00'),\n",
       " Timestamp('2019-01-10 00:00:00'),\n",
       " Timestamp('2019-01-11 00:00:00'),\n",
       " Timestamp('2019-01-12 00:00:00'),\n",
       " Timestamp('2019-01-13 00:00:00'),\n",
       " Timestamp('2019-01-14 00:00:00'),\n",
       " Timestamp('2019-01-15 00:00:00'),\n",
       " Timestamp('2019-01-16 00:00:00'),\n",
       " Timestamp('2019-01-17 00:00:00'),\n",
       " Timestamp('2019-01-18 00:00:00'),\n",
       " Timestamp('2019-01-19 00:00:00'),\n",
       " Timestamp('2019-01-20 00:00:00'),\n",
       " Timestamp('2019-01-21 00:00:00'),\n",
       " Timestamp('2019-01-22 00:00:00'),\n",
       " Timestamp('2019-01-23 00:00:00'),\n",
       " Timestamp('2019-01-24 00:00:00'),\n",
       " Timestamp('2019-01-25 00:00:00'),\n",
       " Timestamp('2019-01-26 00:00:00'),\n",
       " Timestamp('2019-01-27 00:00:00'),\n",
       " Timestamp('2019-01-28 00:00:00'),\n",
       " Timestamp('2019-01-29 00:00:00'),\n",
       " Timestamp('2019-01-30 00:00:00'),\n",
       " Timestamp('2019-01-31 00:00:00'),\n",
       " Timestamp('2019-02-01 00:00:00'),\n",
       " Timestamp('2019-02-02 00:00:00'),\n",
       " Timestamp('2019-02-03 00:00:00'),\n",
       " Timestamp('2019-02-04 00:00:00'),\n",
       " Timestamp('2019-02-05 00:00:00'),\n",
       " Timestamp('2019-02-06 00:00:00'),\n",
       " Timestamp('2019-02-07 00:00:00'),\n",
       " Timestamp('2019-02-08 00:00:00'),\n",
       " Timestamp('2019-02-09 00:00:00'),\n",
       " Timestamp('2019-02-10 00:00:00'),\n",
       " Timestamp('2019-02-11 00:00:00'),\n",
       " Timestamp('2019-02-12 00:00:00'),\n",
       " Timestamp('2019-02-13 00:00:00'),\n",
       " Timestamp('2019-02-14 00:00:00'),\n",
       " Timestamp('2019-02-15 00:00:00'),\n",
       " Timestamp('2019-02-16 00:00:00'),\n",
       " Timestamp('2019-02-17 00:00:00'),\n",
       " Timestamp('2019-02-18 00:00:00'),\n",
       " Timestamp('2019-02-19 00:00:00'),\n",
       " Timestamp('2019-02-20 00:00:00'),\n",
       " Timestamp('2019-02-21 00:00:00'),\n",
       " Timestamp('2019-02-22 00:00:00'),\n",
       " Timestamp('2019-02-23 00:00:00'),\n",
       " Timestamp('2019-02-24 00:00:00'),\n",
       " Timestamp('2019-02-25 00:00:00'),\n",
       " Timestamp('2019-02-26 00:00:00'),\n",
       " Timestamp('2019-02-27 00:00:00'),\n",
       " Timestamp('2019-02-28 00:00:00'),\n",
       " Timestamp('2019-03-01 00:00:00'),\n",
       " Timestamp('2019-03-02 00:00:00'),\n",
       " Timestamp('2019-03-03 00:00:00'),\n",
       " Timestamp('2019-03-04 00:00:00'),\n",
       " Timestamp('2019-03-05 00:00:00'),\n",
       " Timestamp('2019-03-06 00:00:00'),\n",
       " Timestamp('2019-03-07 00:00:00'),\n",
       " Timestamp('2019-03-08 00:00:00'),\n",
       " Timestamp('2019-03-09 00:00:00'),\n",
       " Timestamp('2019-03-10 00:00:00'),\n",
       " Timestamp('2019-03-11 00:00:00'),\n",
       " Timestamp('2019-03-12 00:00:00'),\n",
       " Timestamp('2019-03-13 00:00:00'),\n",
       " Timestamp('2019-03-14 00:00:00'),\n",
       " Timestamp('2019-03-15 00:00:00'),\n",
       " Timestamp('2019-03-16 00:00:00'),\n",
       " Timestamp('2019-03-17 00:00:00'),\n",
       " Timestamp('2019-03-18 00:00:00'),\n",
       " Timestamp('2019-03-19 00:00:00'),\n",
       " Timestamp('2019-03-20 00:00:00'),\n",
       " Timestamp('2019-03-21 00:00:00'),\n",
       " Timestamp('2019-03-22 00:00:00'),\n",
       " Timestamp('2019-03-23 00:00:00'),\n",
       " Timestamp('2019-03-24 00:00:00'),\n",
       " Timestamp('2019-03-25 00:00:00'),\n",
       " Timestamp('2019-03-26 00:00:00'),\n",
       " Timestamp('2019-03-27 00:00:00'),\n",
       " Timestamp('2019-03-28 00:00:00'),\n",
       " Timestamp('2019-03-29 00:00:00'),\n",
       " Timestamp('2019-03-30 00:00:00'),\n",
       " Timestamp('2019-03-31 00:00:00'),\n",
       " Timestamp('2019-04-01 00:00:00'),\n",
       " Timestamp('2019-04-02 00:00:00'),\n",
       " Timestamp('2019-04-03 00:00:00'),\n",
       " Timestamp('2019-04-04 00:00:00'),\n",
       " Timestamp('2019-04-05 00:00:00'),\n",
       " Timestamp('2019-04-06 00:00:00'),\n",
       " Timestamp('2019-04-07 00:00:00'),\n",
       " Timestamp('2019-04-08 00:00:00'),\n",
       " Timestamp('2019-04-09 00:00:00'),\n",
       " Timestamp('2019-04-10 00:00:00'),\n",
       " Timestamp('2019-04-11 00:00:00'),\n",
       " Timestamp('2019-04-12 00:00:00'),\n",
       " Timestamp('2019-04-13 00:00:00'),\n",
       " Timestamp('2019-04-14 00:00:00'),\n",
       " Timestamp('2019-04-15 00:00:00'),\n",
       " Timestamp('2019-04-16 00:00:00'),\n",
       " Timestamp('2019-04-17 00:00:00'),\n",
       " Timestamp('2019-04-18 00:00:00'),\n",
       " Timestamp('2019-04-19 00:00:00'),\n",
       " Timestamp('2019-04-20 00:00:00'),\n",
       " Timestamp('2019-04-21 00:00:00'),\n",
       " Timestamp('2019-04-22 00:00:00'),\n",
       " Timestamp('2019-04-23 00:00:00'),\n",
       " Timestamp('2019-04-24 00:00:00'),\n",
       " Timestamp('2019-04-25 00:00:00'),\n",
       " Timestamp('2019-04-26 00:00:00'),\n",
       " Timestamp('2019-04-27 00:00:00'),\n",
       " Timestamp('2019-04-28 00:00:00'),\n",
       " Timestamp('2019-04-29 00:00:00'),\n",
       " Timestamp('2019-04-30 00:00:00'),\n",
       " Timestamp('2019-05-01 00:00:00'),\n",
       " Timestamp('2019-05-02 00:00:00'),\n",
       " Timestamp('2019-05-03 00:00:00'),\n",
       " Timestamp('2019-05-04 00:00:00'),\n",
       " Timestamp('2019-05-05 00:00:00'),\n",
       " Timestamp('2019-05-06 00:00:00'),\n",
       " Timestamp('2019-05-07 00:00:00'),\n",
       " Timestamp('2019-05-08 00:00:00'),\n",
       " Timestamp('2019-05-09 00:00:00'),\n",
       " Timestamp('2019-05-10 00:00:00'),\n",
       " Timestamp('2019-05-11 00:00:00'),\n",
       " Timestamp('2019-05-12 00:00:00'),\n",
       " Timestamp('2019-05-13 00:00:00'),\n",
       " Timestamp('2019-05-14 00:00:00'),\n",
       " Timestamp('2019-05-15 00:00:00'),\n",
       " Timestamp('2019-05-16 00:00:00'),\n",
       " Timestamp('2019-05-17 00:00:00'),\n",
       " Timestamp('2019-05-18 00:00:00'),\n",
       " Timestamp('2019-05-19 00:00:00'),\n",
       " Timestamp('2019-05-20 00:00:00'),\n",
       " Timestamp('2019-05-21 00:00:00'),\n",
       " Timestamp('2019-05-22 00:00:00'),\n",
       " Timestamp('2019-05-23 00:00:00'),\n",
       " Timestamp('2019-05-24 00:00:00'),\n",
       " Timestamp('2019-05-25 00:00:00'),\n",
       " Timestamp('2019-05-26 00:00:00'),\n",
       " Timestamp('2019-05-27 00:00:00'),\n",
       " Timestamp('2019-05-28 00:00:00'),\n",
       " Timestamp('2019-05-29 00:00:00'),\n",
       " Timestamp('2019-05-30 00:00:00'),\n",
       " Timestamp('2019-05-31 00:00:00'),\n",
       " Timestamp('2019-06-01 00:00:00'),\n",
       " Timestamp('2019-06-02 00:00:00'),\n",
       " Timestamp('2019-06-03 00:00:00'),\n",
       " Timestamp('2019-06-04 00:00:00'),\n",
       " Timestamp('2019-06-05 00:00:00'),\n",
       " Timestamp('2019-06-06 00:00:00'),\n",
       " Timestamp('2019-06-07 00:00:00'),\n",
       " Timestamp('2019-06-08 00:00:00'),\n",
       " Timestamp('2019-06-09 00:00:00'),\n",
       " Timestamp('2019-06-10 00:00:00'),\n",
       " Timestamp('2019-06-11 00:00:00'),\n",
       " Timestamp('2019-06-12 00:00:00'),\n",
       " Timestamp('2019-06-13 00:00:00'),\n",
       " Timestamp('2019-06-14 00:00:00'),\n",
       " Timestamp('2019-06-15 00:00:00'),\n",
       " Timestamp('2019-06-16 00:00:00'),\n",
       " Timestamp('2019-06-17 00:00:00'),\n",
       " Timestamp('2019-06-18 00:00:00'),\n",
       " Timestamp('2019-06-19 00:00:00'),\n",
       " Timestamp('2019-06-20 00:00:00'),\n",
       " Timestamp('2019-06-21 00:00:00'),\n",
       " Timestamp('2019-06-22 00:00:00'),\n",
       " Timestamp('2019-06-23 00:00:00'),\n",
       " Timestamp('2019-06-24 00:00:00'),\n",
       " Timestamp('2019-06-25 00:00:00'),\n",
       " Timestamp('2019-06-26 00:00:00'),\n",
       " Timestamp('2019-06-27 00:00:00'),\n",
       " Timestamp('2019-06-28 00:00:00'),\n",
       " Timestamp('2019-06-29 00:00:00'),\n",
       " Timestamp('2019-06-30 00:00:00'),\n",
       " Timestamp('2019-07-01 00:00:00'),\n",
       " Timestamp('2019-07-02 00:00:00'),\n",
       " Timestamp('2019-07-03 00:00:00'),\n",
       " Timestamp('2019-07-04 00:00:00'),\n",
       " Timestamp('2019-07-05 00:00:00'),\n",
       " Timestamp('2019-07-06 00:00:00'),\n",
       " Timestamp('2019-07-07 00:00:00'),\n",
       " Timestamp('2019-07-13 00:00:00'),\n",
       " Timestamp('2019-07-14 00:00:00'),\n",
       " Timestamp('2019-07-15 00:00:00'),\n",
       " Timestamp('2019-07-16 00:00:00'),\n",
       " Timestamp('2019-07-17 00:00:00'),\n",
       " Timestamp('2019-07-18 00:00:00'),\n",
       " Timestamp('2019-07-19 00:00:00'),\n",
       " Timestamp('2019-07-20 00:00:00'),\n",
       " Timestamp('2019-07-21 00:00:00'),\n",
       " Timestamp('2019-07-22 00:00:00'),\n",
       " Timestamp('2019-07-23 00:00:00'),\n",
       " Timestamp('2019-07-24 00:00:00'),\n",
       " Timestamp('2019-07-25 00:00:00'),\n",
       " Timestamp('2019-07-26 00:00:00'),\n",
       " Timestamp('2019-07-27 00:00:00'),\n",
       " Timestamp('2019-07-28 00:00:00'),\n",
       " Timestamp('2019-07-29 00:00:00'),\n",
       " Timestamp('2019-07-30 00:00:00'),\n",
       " Timestamp('2019-07-31 00:00:00'),\n",
       " Timestamp('2019-08-01 00:00:00'),\n",
       " Timestamp('2019-08-02 00:00:00'),\n",
       " Timestamp('2019-08-03 00:00:00'),\n",
       " Timestamp('2019-08-04 00:00:00'),\n",
       " Timestamp('2019-08-05 00:00:00'),\n",
       " Timestamp('2019-08-06 00:00:00'),\n",
       " Timestamp('2019-08-07 00:00:00'),\n",
       " Timestamp('2019-08-08 00:00:00'),\n",
       " Timestamp('2019-08-09 00:00:00'),\n",
       " Timestamp('2019-08-10 00:00:00'),\n",
       " Timestamp('2019-08-11 00:00:00'),\n",
       " Timestamp('2019-08-12 00:00:00'),\n",
       " Timestamp('2019-08-13 00:00:00'),\n",
       " Timestamp('2019-08-14 00:00:00'),\n",
       " Timestamp('2019-08-15 00:00:00'),\n",
       " Timestamp('2019-08-16 00:00:00'),\n",
       " Timestamp('2019-08-17 00:00:00'),\n",
       " Timestamp('2019-08-18 00:00:00'),\n",
       " Timestamp('2019-08-19 00:00:00'),\n",
       " Timestamp('2019-08-20 00:00:00'),\n",
       " Timestamp('2019-08-21 00:00:00'),\n",
       " Timestamp('2019-08-22 00:00:00'),\n",
       " Timestamp('2019-08-23 00:00:00'),\n",
       " Timestamp('2019-08-24 00:00:00'),\n",
       " Timestamp('2019-08-25 00:00:00'),\n",
       " Timestamp('2019-08-26 00:00:00'),\n",
       " Timestamp('2019-08-27 00:00:00'),\n",
       " Timestamp('2019-08-28 00:00:00'),\n",
       " Timestamp('2019-08-29 00:00:00'),\n",
       " Timestamp('2019-08-30 00:00:00'),\n",
       " Timestamp('2019-08-31 00:00:00'),\n",
       " Timestamp('2019-09-01 00:00:00'),\n",
       " Timestamp('2019-09-02 00:00:00'),\n",
       " Timestamp('2019-09-03 00:00:00'),\n",
       " Timestamp('2019-09-04 00:00:00'),\n",
       " Timestamp('2019-09-05 00:00:00'),\n",
       " Timestamp('2019-09-06 00:00:00'),\n",
       " Timestamp('2019-09-07 00:00:00'),\n",
       " Timestamp('2019-09-08 00:00:00'),\n",
       " Timestamp('2019-09-09 00:00:00'),\n",
       " Timestamp('2019-09-10 00:00:00'),\n",
       " Timestamp('2019-09-11 00:00:00'),\n",
       " Timestamp('2019-09-12 00:00:00'),\n",
       " Timestamp('2019-09-13 00:00:00'),\n",
       " Timestamp('2019-09-14 00:00:00'),\n",
       " Timestamp('2019-09-15 00:00:00'),\n",
       " Timestamp('2019-09-16 00:00:00'),\n",
       " Timestamp('2019-09-17 00:00:00'),\n",
       " Timestamp('2019-09-18 00:00:00'),\n",
       " Timestamp('2019-09-19 00:00:00'),\n",
       " Timestamp('2019-09-20 00:00:00'),\n",
       " Timestamp('2019-09-21 00:00:00'),\n",
       " Timestamp('2019-09-22 00:00:00'),\n",
       " Timestamp('2019-09-23 00:00:00'),\n",
       " Timestamp('2019-09-24 00:00:00'),\n",
       " Timestamp('2019-09-25 00:00:00'),\n",
       " Timestamp('2019-09-26 00:00:00'),\n",
       " Timestamp('2019-09-27 00:00:00'),\n",
       " Timestamp('2019-09-28 00:00:00'),\n",
       " Timestamp('2019-09-29 00:00:00'),\n",
       " Timestamp('2019-09-30 00:00:00'),\n",
       " Timestamp('2019-10-01 00:00:00'),\n",
       " Timestamp('2019-10-02 00:00:00'),\n",
       " Timestamp('2019-10-03 00:00:00'),\n",
       " Timestamp('2019-10-04 00:00:00'),\n",
       " Timestamp('2019-10-05 00:00:00'),\n",
       " Timestamp('2019-10-06 00:00:00'),\n",
       " Timestamp('2019-10-07 00:00:00'),\n",
       " Timestamp('2019-10-08 00:00:00'),\n",
       " Timestamp('2019-10-09 00:00:00'),\n",
       " Timestamp('2019-10-10 00:00:00'),\n",
       " Timestamp('2019-10-11 00:00:00'),\n",
       " Timestamp('2019-10-12 00:00:00'),\n",
       " Timestamp('2019-10-13 00:00:00'),\n",
       " Timestamp('2019-10-14 00:00:00'),\n",
       " Timestamp('2019-10-15 00:00:00'),\n",
       " Timestamp('2019-10-16 00:00:00'),\n",
       " Timestamp('2019-10-17 00:00:00'),\n",
       " Timestamp('2019-10-18 00:00:00'),\n",
       " Timestamp('2019-10-19 00:00:00'),\n",
       " Timestamp('2019-10-20 00:00:00'),\n",
       " Timestamp('2019-10-21 00:00:00'),\n",
       " Timestamp('2019-10-22 00:00:00'),\n",
       " Timestamp('2019-10-23 00:00:00'),\n",
       " Timestamp('2019-10-24 00:00:00'),\n",
       " Timestamp('2019-10-25 00:00:00'),\n",
       " Timestamp('2019-10-26 00:00:00'),\n",
       " Timestamp('2019-10-27 00:00:00'),\n",
       " Timestamp('2019-10-28 00:00:00'),\n",
       " Timestamp('2019-10-29 00:00:00'),\n",
       " Timestamp('2019-10-30 00:00:00'),\n",
       " Timestamp('2019-10-31 00:00:00'),\n",
       " Timestamp('2019-11-01 00:00:00'),\n",
       " Timestamp('2019-11-02 00:00:00'),\n",
       " Timestamp('2019-11-03 00:00:00'),\n",
       " Timestamp('2019-11-04 00:00:00'),\n",
       " Timestamp('2019-11-05 00:00:00'),\n",
       " Timestamp('2019-11-06 00:00:00'),\n",
       " Timestamp('2019-11-07 00:00:00'),\n",
       " Timestamp('2019-11-08 00:00:00'),\n",
       " Timestamp('2019-11-09 00:00:00'),\n",
       " Timestamp('2019-11-10 00:00:00'),\n",
       " Timestamp('2019-11-11 00:00:00'),\n",
       " Timestamp('2019-11-12 00:00:00'),\n",
       " Timestamp('2019-11-13 00:00:00'),\n",
       " Timestamp('2019-11-14 00:00:00'),\n",
       " Timestamp('2019-11-15 00:00:00'),\n",
       " Timestamp('2019-11-16 00:00:00'),\n",
       " Timestamp('2019-11-17 00:00:00'),\n",
       " Timestamp('2019-11-18 00:00:00'),\n",
       " Timestamp('2019-11-19 00:00:00'),\n",
       " Timestamp('2019-11-20 00:00:00'),\n",
       " Timestamp('2019-11-21 00:00:00'),\n",
       " Timestamp('2019-11-22 00:00:00'),\n",
       " Timestamp('2019-11-23 00:00:00'),\n",
       " Timestamp('2019-11-24 00:00:00'),\n",
       " Timestamp('2019-11-25 00:00:00'),\n",
       " Timestamp('2019-11-26 00:00:00'),\n",
       " Timestamp('2019-11-27 00:00:00'),\n",
       " Timestamp('2019-11-28 00:00:00'),\n",
       " Timestamp('2019-11-29 00:00:00'),\n",
       " Timestamp('2019-11-30 00:00:00'),\n",
       " Timestamp('2019-12-01 00:00:00'),\n",
       " Timestamp('2019-12-02 00:00:00'),\n",
       " Timestamp('2019-12-03 00:00:00'),\n",
       " Timestamp('2019-12-04 00:00:00'),\n",
       " Timestamp('2019-12-05 00:00:00'),\n",
       " Timestamp('2019-12-06 00:00:00'),\n",
       " Timestamp('2019-12-07 00:00:00'),\n",
       " Timestamp('2019-12-08 00:00:00'),\n",
       " Timestamp('2019-12-09 00:00:00'),\n",
       " Timestamp('2019-12-10 00:00:00'),\n",
       " Timestamp('2019-12-11 00:00:00'),\n",
       " Timestamp('2019-12-12 00:00:00'),\n",
       " Timestamp('2019-12-13 00:00:00'),\n",
       " Timestamp('2019-12-14 00:00:00'),\n",
       " Timestamp('2019-12-15 00:00:00'),\n",
       " Timestamp('2019-12-16 00:00:00'),\n",
       " Timestamp('2019-12-17 00:00:00'),\n",
       " Timestamp('2019-12-18 00:00:00'),\n",
       " Timestamp('2019-12-19 00:00:00'),\n",
       " Timestamp('2019-12-20 00:00:00'),\n",
       " Timestamp('2019-12-21 00:00:00'),\n",
       " Timestamp('2019-12-22 00:00:00'),\n",
       " Timestamp('2019-12-23 00:00:00'),\n",
       " Timestamp('2019-12-24 00:00:00'),\n",
       " Timestamp('2019-12-25 00:00:00'),\n",
       " Timestamp('2019-12-26 00:00:00'),\n",
       " Timestamp('2019-12-27 00:00:00'),\n",
       " Timestamp('2019-12-28 00:00:00'),\n",
       " Timestamp('2019-12-29 00:00:00'),\n",
       " Timestamp('2019-12-30 00:00:00'),\n",
       " Timestamp('2019-12-31 00:00:00'),\n",
       " Timestamp('2020-01-01 00:00:00'),\n",
       " Timestamp('2020-01-02 00:00:00'),\n",
       " Timestamp('2020-01-03 00:00:00'),\n",
       " Timestamp('2020-01-04 00:00:00'),\n",
       " Timestamp('2020-01-05 00:00:00'),\n",
       " Timestamp('2020-01-06 00:00:00'),\n",
       " Timestamp('2020-01-07 00:00:00'),\n",
       " Timestamp('2020-01-08 00:00:00'),\n",
       " Timestamp('2020-01-09 00:00:00'),\n",
       " Timestamp('2020-01-10 00:00:00'),\n",
       " Timestamp('2020-01-11 00:00:00'),\n",
       " Timestamp('2020-01-12 00:00:00'),\n",
       " Timestamp('2020-01-13 00:00:00'),\n",
       " Timestamp('2020-01-14 00:00:00'),\n",
       " Timestamp('2020-01-15 00:00:00'),\n",
       " Timestamp('2020-01-16 00:00:00'),\n",
       " Timestamp('2020-01-17 00:00:00'),\n",
       " Timestamp('2020-01-18 00:00:00'),\n",
       " Timestamp('2020-01-19 00:00:00'),\n",
       " Timestamp('2020-01-20 00:00:00'),\n",
       " Timestamp('2020-01-21 00:00:00'),\n",
       " Timestamp('2020-01-22 00:00:00'),\n",
       " Timestamp('2020-01-23 00:00:00'),\n",
       " Timestamp('2020-01-24 00:00:00'),\n",
       " Timestamp('2020-01-25 00:00:00'),\n",
       " Timestamp('2020-01-26 00:00:00'),\n",
       " Timestamp('2020-01-27 00:00:00'),\n",
       " Timestamp('2020-01-28 00:00:00'),\n",
       " Timestamp('2020-01-29 00:00:00'),\n",
       " Timestamp('2020-01-30 00:00:00'),\n",
       " Timestamp('2020-01-31 00:00:00'),\n",
       " Timestamp('2020-02-01 00:00:00'),\n",
       " Timestamp('2020-02-02 00:00:00'),\n",
       " Timestamp('2020-02-03 00:00:00'),\n",
       " Timestamp('2020-02-04 00:00:00'),\n",
       " Timestamp('2020-02-05 00:00:00'),\n",
       " Timestamp('2020-02-06 00:00:00'),\n",
       " Timestamp('2020-02-07 00:00:00'),\n",
       " Timestamp('2020-02-08 00:00:00'),\n",
       " Timestamp('2020-02-09 00:00:00'),\n",
       " Timestamp('2020-02-10 00:00:00'),\n",
       " Timestamp('2020-02-11 00:00:00'),\n",
       " Timestamp('2020-02-12 00:00:00'),\n",
       " Timestamp('2020-02-13 00:00:00'),\n",
       " Timestamp('2020-02-14 00:00:00'),\n",
       " Timestamp('2020-02-15 00:00:00'),\n",
       " Timestamp('2020-02-16 00:00:00'),\n",
       " Timestamp('2020-02-17 00:00:00'),\n",
       " Timestamp('2020-02-18 00:00:00'),\n",
       " Timestamp('2020-02-19 00:00:00'),\n",
       " Timestamp('2020-02-20 00:00:00'),\n",
       " Timestamp('2020-02-21 00:00:00'),\n",
       " Timestamp('2020-02-22 00:00:00'),\n",
       " Timestamp('2020-02-23 00:00:00'),\n",
       " Timestamp('2020-02-24 00:00:00'),\n",
       " Timestamp('2020-02-25 00:00:00'),\n",
       " Timestamp('2020-02-26 00:00:00'),\n",
       " Timestamp('2020-02-27 00:00:00'),\n",
       " Timestamp('2020-02-28 00:00:00'),\n",
       " Timestamp('2020-02-29 00:00:00'),\n",
       " Timestamp('2020-03-01 00:00:00'),\n",
       " Timestamp('2020-03-02 00:00:00'),\n",
       " Timestamp('2020-03-03 00:00:00'),\n",
       " Timestamp('2020-03-04 00:00:00'),\n",
       " Timestamp('2020-03-05 00:00:00'),\n",
       " Timestamp('2020-03-06 00:00:00'),\n",
       " Timestamp('2020-03-07 00:00:00'),\n",
       " Timestamp('2020-03-08 00:00:00'),\n",
       " Timestamp('2020-03-09 00:00:00'),\n",
       " Timestamp('2020-03-10 00:00:00'),\n",
       " Timestamp('2020-03-11 00:00:00'),\n",
       " Timestamp('2020-03-12 00:00:00'),\n",
       " Timestamp('2020-03-13 00:00:00'),\n",
       " Timestamp('2020-03-14 00:00:00'),\n",
       " Timestamp('2020-03-15 00:00:00'),\n",
       " Timestamp('2020-03-16 00:00:00'),\n",
       " Timestamp('2020-03-17 00:00:00'),\n",
       " Timestamp('2020-03-18 00:00:00'),\n",
       " Timestamp('2020-03-19 00:00:00'),\n",
       " Timestamp('2020-03-20 00:00:00'),\n",
       " Timestamp('2020-03-21 00:00:00'),\n",
       " Timestamp('2020-03-22 00:00:00'),\n",
       " Timestamp('2020-03-23 00:00:00'),\n",
       " Timestamp('2020-03-24 00:00:00'),\n",
       " Timestamp('2020-03-25 00:00:00'),\n",
       " Timestamp('2020-03-26 00:00:00'),\n",
       " Timestamp('2020-03-27 00:00:00'),\n",
       " Timestamp('2020-03-28 00:00:00'),\n",
       " Timestamp('2020-03-29 00:00:00'),\n",
       " Timestamp('2020-03-30 00:00:00'),\n",
       " Timestamp('2020-03-31 00:00:00'),\n",
       " Timestamp('2020-04-01 00:00:00'),\n",
       " Timestamp('2020-04-02 00:00:00'),\n",
       " Timestamp('2020-04-03 00:00:00'),\n",
       " Timestamp('2020-04-04 00:00:00'),\n",
       " Timestamp('2020-04-05 00:00:00'),\n",
       " Timestamp('2020-04-06 00:00:00'),\n",
       " Timestamp('2020-04-07 00:00:00'),\n",
       " Timestamp('2020-04-08 00:00:00'),\n",
       " Timestamp('2020-04-09 00:00:00'),\n",
       " Timestamp('2020-04-10 00:00:00'),\n",
       " Timestamp('2020-04-11 00:00:00'),\n",
       " Timestamp('2020-04-12 00:00:00'),\n",
       " Timestamp('2020-04-13 00:00:00'),\n",
       " Timestamp('2020-04-14 00:00:00'),\n",
       " Timestamp('2020-04-15 00:00:00'),\n",
       " Timestamp('2020-04-16 00:00:00'),\n",
       " Timestamp('2020-04-17 00:00:00'),\n",
       " Timestamp('2020-04-18 00:00:00'),\n",
       " Timestamp('2020-04-19 00:00:00'),\n",
       " Timestamp('2020-04-20 00:00:00'),\n",
       " Timestamp('2020-04-21 00:00:00'),\n",
       " Timestamp('2020-04-22 00:00:00'),\n",
       " Timestamp('2020-04-23 00:00:00'),\n",
       " Timestamp('2020-04-24 00:00:00'),\n",
       " Timestamp('2020-04-25 00:00:00'),\n",
       " Timestamp('2020-04-26 00:00:00'),\n",
       " Timestamp('2020-04-27 00:00:00'),\n",
       " Timestamp('2020-04-28 00:00:00'),\n",
       " Timestamp('2020-04-29 00:00:00'),\n",
       " Timestamp('2020-04-30 00:00:00'),\n",
       " Timestamp('2020-05-01 00:00:00'),\n",
       " Timestamp('2020-05-02 00:00:00'),\n",
       " Timestamp('2020-05-03 00:00:00'),\n",
       " Timestamp('2020-05-04 00:00:00'),\n",
       " Timestamp('2020-05-05 00:00:00'),\n",
       " Timestamp('2020-05-06 00:00:00'),\n",
       " Timestamp('2020-05-07 00:00:00'),\n",
       " Timestamp('2020-05-08 00:00:00'),\n",
       " Timestamp('2020-05-09 00:00:00'),\n",
       " Timestamp('2020-05-10 00:00:00'),\n",
       " Timestamp('2020-05-11 00:00:00'),\n",
       " Timestamp('2020-05-12 00:00:00'),\n",
       " Timestamp('2020-05-13 00:00:00'),\n",
       " Timestamp('2020-05-14 00:00:00'),\n",
       " Timestamp('2020-05-15 00:00:00'),\n",
       " Timestamp('2020-05-16 00:00:00'),\n",
       " Timestamp('2020-05-17 00:00:00'),\n",
       " Timestamp('2020-05-18 00:00:00'),\n",
       " Timestamp('2020-05-19 00:00:00'),\n",
       " Timestamp('2020-05-20 00:00:00'),\n",
       " Timestamp('2020-05-21 00:00:00'),\n",
       " Timestamp('2020-05-22 00:00:00'),\n",
       " Timestamp('2020-05-23 00:00:00')}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-caution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "promotional-sequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonenv\\base3.7\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000027CFFC6B048>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df2.groupby(pd.Grouper(key='Dates', freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime import forecasting as FC\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.arima import ARIMA, AutoARIMA\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import (\n",
    "    EnsembleForecaster,\n",
    "   # MultiplexForecaster,\n",
    "    ReducedForecaster,\n",
    "    TransformedTargetForecaster)\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "#from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.forecasting.model_selection import ( ExpandingWindowSplitter,  ForecastingGridSearchCV,  SlidingWindowSplitter,\n",
    "    temporal_train_test_split,\n",
    ")\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.performance_metrics.forecasting import sMAPE, smape_loss\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "#simplefilter(\"ignore\", FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "muslim-abortion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Punjab</th>\n",
       "      <th>Haryana</th>\n",
       "      <th>Rajasthan</th>\n",
       "      <th>Delhi</th>\n",
       "      <th>UP</th>\n",
       "      <th>Uttarakhand</th>\n",
       "      <th>HP</th>\n",
       "      <th>J&amp;K</th>\n",
       "      <th>Chandigarh</th>\n",
       "      <th>...</th>\n",
       "      <th>Odisha</th>\n",
       "      <th>West Bengal</th>\n",
       "      <th>Sikkim</th>\n",
       "      <th>Arunachal Pradesh</th>\n",
       "      <th>Assam</th>\n",
       "      <th>Manipur</th>\n",
       "      <th>Meghalaya</th>\n",
       "      <th>Mizoram</th>\n",
       "      <th>Nagaland</th>\n",
       "      <th>Tripura</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2019</td>\n",
       "      <td>119.9</td>\n",
       "      <td>130.3</td>\n",
       "      <td>234.1</td>\n",
       "      <td>85.8</td>\n",
       "      <td>313.9</td>\n",
       "      <td>40.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2</td>\n",
       "      <td>108.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>21.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/01/2019</td>\n",
       "      <td>121.9</td>\n",
       "      <td>133.5</td>\n",
       "      <td>240.2</td>\n",
       "      <td>85.5</td>\n",
       "      <td>311.8</td>\n",
       "      <td>39.3</td>\n",
       "      <td>30.1</td>\n",
       "      <td>54.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>67.9</td>\n",
       "      <td>110.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>23.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/01/2019</td>\n",
       "      <td>118.8</td>\n",
       "      <td>128.2</td>\n",
       "      <td>239.8</td>\n",
       "      <td>83.5</td>\n",
       "      <td>320.7</td>\n",
       "      <td>38.1</td>\n",
       "      <td>30.1</td>\n",
       "      <td>53.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>66.3</td>\n",
       "      <td>106.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>21.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/01/2019</td>\n",
       "      <td>121.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>239.1</td>\n",
       "      <td>79.2</td>\n",
       "      <td>299.0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>51.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>65.8</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/01/2019</td>\n",
       "      <td>121.4</td>\n",
       "      <td>132.6</td>\n",
       "      <td>240.4</td>\n",
       "      <td>76.6</td>\n",
       "      <td>286.8</td>\n",
       "      <td>39.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>62.9</td>\n",
       "      <td>106.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>21.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Punjab  Haryana  Rajasthan  Delhi     UP  Uttarakhand    HP  \\\n",
       "0  02/01/2019   119.9    130.3      234.1   85.8  313.9         40.7  30.0   \n",
       "1  03/01/2019   121.9    133.5      240.2   85.5  311.8         39.3  30.1   \n",
       "2  04/01/2019   118.8    128.2      239.8   83.5  320.7         38.1  30.1   \n",
       "3  05/01/2019   121.0    127.5      239.1   79.2  299.0         39.2  30.2   \n",
       "4  06/01/2019   121.4    132.6      240.4   76.6  286.8         39.2  31.0   \n",
       "\n",
       "    J&K  Chandigarh  ...  Odisha  West Bengal  Sikkim  Arunachal Pradesh  \\\n",
       "0  52.5         5.0  ...    70.2        108.2     2.0                2.1   \n",
       "1  54.1         4.9  ...    67.9        110.2     1.9                2.2   \n",
       "2  53.2         4.8  ...    66.3        106.8     1.7                2.2   \n",
       "3  51.5         4.3  ...    65.8        107.0     2.0                2.2   \n",
       "4  53.2         4.3  ...    62.9        106.4     2.0                2.2   \n",
       "\n",
       "   Assam  Manipur  Meghalaya  Mizoram  Nagaland  Tripura  \n",
       "0   21.7      2.7        6.1      1.9       2.2      3.4  \n",
       "1   23.4      2.4        6.5      1.8       2.2      3.6  \n",
       "2   21.7      2.4        6.3      1.7       2.2      3.5  \n",
       "3   22.5      2.7        5.7      1.8       2.3      3.5  \n",
       "4   21.7      2.7        6.2      1.9       2.3      3.3  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"../_dataset/IndiaPowerConsumtion/dataset_tk.csv\"\n",
    "raw = pd.read_csv(path)\n",
    "# raw=raw.rename(columns = {\"Unnamed: 0\":'Datetime'})\n",
    "# raw['Date'] = pd.to_datetime(raw['Datetime'], format='%d/%m/%Y %H:%M:%S').dt.date\n",
    "# raw['Datetime'] = pd.to_datetime(raw['Datetime'], format='%d/%m/%Y %H:%M:%S')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "induced-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = raw[[\"Date\",\"UP\"]]\n",
    "df1.to_csv('temp/Power_tk.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atomic-america",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period\n",
       "2019-02-01    313.9\n",
       "2019-03-01    311.8\n",
       "2019-04-01    320.7\n",
       "2019-05-01    299.0\n",
       "2019-06-01    286.8\n",
       "Freq: D, Name: UP Power Consumtion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.read_csv('temp/Power_tk.csv',index_col=0, squeeze=True, dtype={1: np.float})\n",
    "y.index = pd.PeriodIndex(y.index, freq=\"D\", name=\"Period\")\n",
    "y.name = \"UP Power Consumtion\"\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "italic-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = load_airline()\n",
    "# plot_series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binding-annual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "medieval-modem",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-10-07    2\n",
       "2019-11-07    2\n",
       "2019-09-07    2\n",
       "2019-08-07    2\n",
       "2019-12-07    2\n",
       "             ..\n",
       "2019-06-16    1\n",
       "2019-06-15    1\n",
       "2019-06-14    1\n",
       "2019-06-13    1\n",
       "2020-05-23    1\n",
       "Freq: D, Name: Period, Length: 498, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(y);\n",
    "plt.xticks(rotation=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from sktime.performance_metrics.forecasting import smape_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-humor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train, y_test = temporal_train_test_split(y, test_size=200)\n",
    "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\n",
    "plt.xticks(rotation=25)\n",
    "print(y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "forecaster = ThetaForecaster(sp=12)  # monthly seasonal periodicity\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test,y_pred ,labels=[\"y_train\", \"y_test\",\"y_pred\"])\n",
    "smape_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "smape_loss(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = ForecastingHorizon(y.index, is_relative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-termination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-budapest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
