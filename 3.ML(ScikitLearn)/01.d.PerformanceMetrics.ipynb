{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hungry-syracuse",
   "metadata": {},
   "source": [
    "# <center>Performance Metrics(Parameters) for classification:</u></center>\n",
    "\n",
    "## 1. [Confusion Matrix](e.ConfusionMatrix.ipynb)\n",
    "\n",
    "![](_pic/img-performance/ConfusionMatrics.png)\n",
    "\n",
    "**Terms associated with Confusion matrix:**\n",
    "\n",
    "**1. True Positives (TP):** \n",
    "\n",
    "- True positives are the cases when the actual class of the data point was 1(True) and the predicted is also 1(True)\n",
    "\n",
    "**2. True Negatives (TN):** \n",
    "\n",
    "- True negatives are the cases when the actual class of the data point was 0(False) and the predicted is also 0(False)\n",
    "\n",
    "**3. False Positives (FP):**\n",
    "\n",
    "- False positives are the cases when the actual class of the data point was 0(False) and the predicted is 1(True). False is because the model has predicted incorrectly and positive because the class predicted was a positive one. (1)\n",
    "\n",
    "**4. False Negatives (FN):** \n",
    "\n",
    "- False negatives are the cases when the actual class of the data point was 1(True) and the predicted is 0(False). False is because the model has predicted incorrectly and negative because the class predicted was a negative one. (0) \n",
    "\n",
    "**Accuracy** measures how well the test predicts both True and Negative classes.\n",
    "(Overall correctness of model) \n",
    "\n",
    "<center>$\\begin{align*}Accuracy = \\frac{TP +TN}{TP + FP + FN + TN}\\end{align*}$</center>\n",
    "\n",
    "\n",
    "**Sensitivity (Recall or True positive rate)** measures the proportion of positives that are correctly identified as such \n",
    "(Accuracy of class 1)\n",
    "\n",
    " <center>$\\begin{align*}Recall =\\frac{TP }{TP + FN}\\end{align*}$</center>\n",
    "\n",
    "\n",
    "**Specificity (True negative rate)** measures the proportion of negatives that are correctly identified as such. \n",
    "(Accuracy of class 0)\n",
    "\n",
    " <center>$\\begin{align*}Specificity = \\frac{TN}{TN + FP}\\end{align*}$</center>\n",
    " \n",
    "**Precision (Positive Predictive Value)** is intuitively the ability of the classifier not to label as positive a sample that is\n",
    "negative.\n",
    "(How Many predicted 1 are actually 1)\n",
    "\n",
    "<center>$\\begin{align*}Precision =\\frac{TP }{FP + TP}\\end{align*}$</center>\n",
    "\n",
    "**Negative Predictive Value** \n",
    "\n",
    "<center>$\\begin{align*}Negative Predictive Value =\\frac{TN}{FN + TN}\\end{align*}$</center>\n",
    "\n",
    "\n",
    "**False Positive Rate (FPR) :**\n",
    "The false positive rate is the proportion of all negatives that still yield positive test outcomes.\n",
    "\n",
    " <center>$\\begin{align*}False Positive Rate= \\frac{FP}{FP + TN}\\end{align*}$</center>\n",
    " \n",
    " \n",
    "**F-1 Score:**\n",
    "If we have immbalanced data like in titanic we have majority of sample belonging to 0 class.\n",
    "\n",
    "Or suppose consider:\n",
    "\n",
    "- 100 samples(instances)->class 0\n",
    "\n",
    "- 20 samples(instances)->class 1\n",
    "\n",
    "The above data is immbalanced.\n",
    "\n",
    "So ,with immbalanced data we should test model performance by using F-1 score.\n",
    "\n",
    "<center> $\\begin{align*}F1 = 2 *\\frac{precision * recall}{precision + recall} \\end{align*}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-vintage",
   "metadata": {},
   "source": [
    "**Load dataset/Clean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "choice-opening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  EstimatedSalary  Purchased\n",
       "0       1   19            19000          0\n",
       "1       1   35            20000          0\n",
       "2       2   26            43000          0\n",
       "3       2   27            57000          0\n",
       "4       1   19            76000          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('_dataset/Dataset-ConfusionMatrix/Online_Ads.csv')\n",
    "#hot encoding\n",
    "df['Gender']=df['Gender'].map({'Male':1, 'Female':2})\n",
    "X=df.loc[:,('Age','EstimatedSalary','Gender')].values\n",
    "y=df.loc[:,'Purchased'].values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-western",
   "metadata": {},
   "source": [
    "**Preprocessing (Standard Scaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "roman-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "sc=preprocessing.StandardScaler()\n",
    "X_new=sc.fit_transform(X.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brutal-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-circuit",
   "metadata": {},
   "source": [
    "**Model selection (Train Test Split)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "danish-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_new,y,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bibliographic-beginning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-judge",
   "metadata": {},
   "source": [
    "**Model Train/Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "clinical-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log=LogisticRegression()\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impressed-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=log.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-husband",
   "metadata": {},
   "source": [
    "**Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "regulated-building",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "composed-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn=neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "civic-score",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-plaintiff",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "      - sklearn.metrics.confusion_matrix(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "nonprofit-mailman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :0.9\n",
      "Sensitivity = Recall = TruePositiveRate = TPR :0.9285714285714286\n",
      "Specificity :0.8888888888888888\n",
      "Precision :0.7647058823529411\n",
      "FalsePositiveRate :0.1111111111111111\n",
      "F1Score :0.8387096774193549\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cm=metrics.confusion_matrix(y_test,pred_test)\n",
    "\n",
    "#Mannual\n",
    "tn=cm[0][0]\n",
    "fp=cm[0][1]\n",
    "fn=cm[1][0]\n",
    "tp=cm[1][1]\n",
    "\n",
    "Accuracy=(tn+tp)/(tn+fp+fn+tp)\n",
    "Sensitivity = Recall = TruePositiveRate = TPR =tp/(tp+fn)\n",
    "Specificity=tn/(tn+fp)\n",
    "Precision=tp/(fp+tp)\n",
    "FalsePositiveRate= FPR = (fp/(fp + tn))\n",
    "F1Score=2*(Precision*Recall)/(Precision + Recall)\n",
    "print(\"Accuracy :\"+str(Accuracy))\n",
    "print(\"Sensitivity = Recall = TruePositiveRate = TPR :\"+str(Recall))\n",
    "print(\"Specificity :\"+str(Specificity))\n",
    "print(\"Precision :\"+str(Precision))\n",
    "print(\"FalsePositiveRate :\"+str(FalsePositiveRate))\n",
    "print(\"F1Score :\"+str(F1Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "concrete-government",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "alpine-jewel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "liquid-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387096774193549"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "thick-dodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-contractor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-schema",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
