{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functional-petroleum",
   "metadata": {},
   "source": [
    "**What is a neural network ?**\n",
    "\n",
    "Based on nature, neural networks are the usual representation we make of the brain : neurons interconnected to other neurons which forms a network. A simple information transits in a lot of them before becoming an actual thing, like “move the hand to pick up this pencil”.\n",
    "The operation of a complete neural network is straightforward : one enter variables as inputs (for example an image if the neural network is supposed to tell what is on an image), and after some calculations, an output is returned (following the first example, giving an image of a cat should return the word “cat”).\n",
    "\n",
    "Now, you should know that artificial neural network are usually put on columns, so that a neuron of the column n can only be connected to neurons from columns n-1 and n+1. There are few types of networks that use a different architecture, but we will focus on the simplest for now.\n",
    "So, we can represent an artificial neural network like that :\n",
    "Image for post\n",
    "![](_pic/1_v1ohAG82xmU6WGsG2hoE8g.png)\n",
    "\n",
    "<center>Figure 1 — Representation of a neural network</center>\n",
    "Neural networks can usually be read from left to right. Here, the first layer is the layer in which inputs are entered. There are 2 internals layers (called hidden layers) that do some math, and one last layer that contains all the possible outputs. Don’t bother with the “+1”s at the bottom of every columns. It is something called “bias” and we’ll talk about that later.\n",
    "\n",
    "By the way, the term “deep learning” comes from neural networks that contains several hidden layers, also called “deep neural networks” . The Figure 1 can be considered as one.\n",
    "\n",
    "**What does a neuron do ?**\n",
    "\n",
    "The operations done by each neurons are pretty simple :\n",
    "Image for post\n",
    "![](_pic/1_UA30b0mJUPYoPvN8yJr2iQ.jpeg)\n",
    "\n",
    "<center>Figure 2 — Operations done by a neuron</center>\n",
    "First, it adds up the value of every neurons from the previous column it is connected to. On the Figure 2, there are 3 inputs (x1, x2, x3) coming to the neuron, so 3 neurons of the previous column are connected to our neuron.\n",
    "\n",
    "This value is multiplied, before being added, by another variable called “weight” (w1, w2, w3) which determines the connection between the two neurons. Each connection of neurons has its own weight, and those are the only values that will be modified during the learning process.\n",
    "Moreover, a bias value may be added to the total value calculated. It is not a value coming from a specific neuron and is chosen before the learning phase, but can be useful for the network.\n",
    "After all those summations, the neuron finally applies a function called “activation function” to the obtained value.\n",
    "\n",
    "![](_pic/1_JHWL_71qml0kP_Imyx4zBg.png)\n",
    "\n",
    "<center>Figure 3 — Sigmoid function</center>\n",
    "\n",
    "The so-called activation function usually serves to turn the total value calculated before to a number between 0 and 1 (done for example by a sigmoid function shown by Figure 3). Other function exist and may change the limits of our function, but keeps the same aim of limiting the value.\n",
    "That’s all a neuron does ! Take all values from connected neurons multiplied by their respective weight, add them, and apply an activation function. Then, the neuron is ready to send its new value to other neurons.\n",
    "\n",
    "After every neurons of a column did it, the neural network passes to the next column. In the end, the last values obtained should be one usable to determine the desired output.\n",
    "\n",
    "Now that we understand what a neuron does, we could possibly create any network we want. However, there are other operations to implement to make a neural network learn.\n",
    "\n",
    "**How does a neural network learn ?**\n",
    "\n",
    "Yep, creating variables and making them interact with each other is great, but that is not enough to make the whole neural network learn by itself. We need to prepare a lot of data to give to our network. Those data include the inputs and the output expected from the neural network.\n",
    "Let’s take a look at how the learning process works :\n",
    "\n",
    "First of all, remember that when an input is given to the neural network, it returns an output. On the first try, it can’t get the right output by its own (except with luck) and that is why, during the learning phase, every inputs come with its label, explaining what output the neural network should have guessed. If the choice is the good one, actual parameters are kept and the next input is given. However, if the obtained output doesn’t match the label, weights are changed. Those are the only variables that can be changed during the learning phase. This process may be imagined as multiple buttons, that are turned into different possibilities every times an input isn’t guessed correctly.\n",
    "\n",
    "To determine which weight is better to modify, a particular process, called “backpropagation” is done. We won’t linger too much on that, since the neural network we will build doesn’t use this exact process, but it consists on going back on the neural network and inspect every connection to check how the output would behave according to a change on the weight.\n",
    "\n",
    "Finally, there is a last parameter to know to be able to control the way the neural network learns : the “learning rate”. The name says it all, this new value determines on what speed the neural network will learn, or more specifically how it will modify a weight, little by little or by bigger steps. 1 is generally a good value for that parameter.\n",
    "\n",
    "**Perceptron**\n",
    "\n",
    "Okay, we know the basics, let’s check about the neural network we will create. The one explained here is called a Perceptron and is the first neural network ever created. It consists on 2 neurons in the inputs column and 1 neuron in the output column. This configuration allows to create a simple classifier to distinguish 2 groups. To better understand the possibilities and the limitations, let’s see a quick example (which doesn’t have much interest except to understand) :\n",
    "- Let’s say you want your neural network to be able to return outputs according to the rules of the “inclusive or”. Reminder :\n",
    "\n",
    "![](_pic/1_LZGp64tc2qAovsLF4rqKNg.png)\n",
    "\n",
    "1. if A is true and B is true, then A or B is true.\n",
    "2. if A is true and B is false, then A or B is true.\n",
    "3. if A is false and B is true, then A or B is true.\n",
    "4. if A is false and B is false, then A or B is false.\n",
    "\n",
    "If you replace the “true”s by 1 and the “false”s by 0 and put the 4 possibilities as points with coordinates on a plan, then you realize the two final groups “false” and “true” may be separated by a single line. This is what a Perceptron can do.\n",
    "\n",
    "On the other hand, if we check the case of the “exclusive or” (in which the case “true or true” (the point (1,1)) is false), then we can see that a simple line cannot separate the two groups, and a Perceptron isn’t able to deal with this problem.\n",
    "\n",
    "So, the Perceptron is indeed not a very efficient neural network, but it is simple to create and may still be useful as a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-cartridge",
   "metadata": {},
   "source": [
    "Creating our own simple neural network\n",
    "\n",
    "Let’s create a neural network from scratch with Python (3.x in the example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "experimental-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, random, os\n",
    "lr = 1 #learning rate\n",
    "bias = 1 #value of bias\n",
    "weights = [random.random(),random.random(),random.random()] \n",
    "#weights generated in a list (3 weights in total for 2 neurons and the bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "portable-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(input1, input2, output) :\n",
    "    outputP = input1*weights[0]+input2*weights[1]+bias*weights[2]\n",
    "    if outputP > 0 : #activation function (here Heaviside)\n",
    "        outputP = 1\n",
    "    else :\n",
    "        outputP = 0\n",
    "    error = output - outputP\n",
    "    weights[0] += error * input1 * lr\n",
    "    weights[1] += error * input2 * lr\n",
    "    weights[2] += error * bias * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eight-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50) :\n",
    "    Perceptron(1,1,1) #True or true\n",
    "    Perceptron(1,0,1) #True or false\n",
    "    Perceptron(0,1,1) #False or true\n",
    "    Perceptron(0,0,0) #False or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "three-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "51\n",
      "50 or 51 is :  1\n"
     ]
    }
   ],
   "source": [
    "x = int(input())\n",
    "y = int(input())\n",
    "outputP = x*weights[0] + y*weights[1] + bias*weights[2]\n",
    "if outputP > 0 : #activation function\n",
    "    outputP = 1\n",
    "else :\n",
    "    outputP = 0\n",
    "print(x, \"or\", y, \"is : \", outputP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comparable-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputP = 1/(1+numpy.exp(-outputP)) #sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-keyboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
