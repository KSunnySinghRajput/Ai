{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear Regression \n",
    "\n",
    "- Batch Gradient Descent: entire dataset.\n",
    "- Stochastic Gradient Descent (SGD): mini-batches. \n",
    "- In TensorFlow:\n",
    "\n",
    "<pre>optimizer = tf.train.GradientDescentOptimizer(learning_rate)</pre>\n",
    "<pre>train = optimizer.minimize(loss)</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.random.randn(2000,3)\n",
    "w_real = [0.4, 0.6, 0.2]\n",
    "b_real = -0.3 \n",
    "noise = np.random.randn(1,2000)*0.1 \n",
    "y_data = np.matmul(w_real, x_data.T)+b_real+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[ 0.4324733 ,  0.62102544,  0.21289678]], dtype=float32), -0.26101521]\n",
      "5 [array([[ 0.39815262,  0.59838271,  0.20108758]], dtype=float32), -0.30086589]\n",
      "10 [array([[ 0.39815292,  0.59838313,  0.20108768]], dtype=float32), -0.30086562]\n"
     ]
    }
   ],
   "source": [
    "num_iters = 10 \n",
    "g = tf.Graph()\n",
    "wb = []\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]], dtype=tf.float32, name='W')\n",
    "        b = tf.Variable(0, dtype=tf.float32, name='b')\n",
    "        y_pred = tf.matmul(w, tf.transpose(x))+b\n",
    "        \n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "        \n",
    "    with tf.name_scope('training') as scope:\n",
    "        lr = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(num_iters):\n",
    "            sess.run(train, {x:x_data, y_true:y_data})\n",
    "            if(step%5==0):\n",
    "                print(step, sess.run([w,b]))\n",
    "                wb.append(sess.run([w,b]))\n",
    "                \n",
    "        print(10, sess.run([w,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x_data = np.random.randn(20000,3)\n",
    "w_real = [0.4, 0.6, 0.2]\n",
    "b_real = -0.3\n",
    "wb = np.matmul(w_real,x_data.T)+b_real\n",
    "\n",
    "y_data_bef_noise = sigmoid(wb)\n",
    "y_data = np.random.binomial(1, y_data_bef_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /srv/conda/envs/notebook/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "0 [array([[0.0450779 , 0.06196544, 0.02131424]], dtype=float32), -0.032474972]\n",
      "5 [array([[0.20027295, 0.27623105, 0.09478565]], dtype=float32), -0.14451593]\n",
      "10 [array([[0.28493407, 0.3939746 , 0.13491543]], dtype=float32), -0.20562238]\n",
      "15 [array([[0.33391127, 0.46251875, 0.15813442]], dtype=float32), -0.24080153]\n",
      "20 [array([[0.36336213, 0.50395566, 0.1720913 ]], dtype=float32), -0.26180792]\n",
      "25 [array([[0.38149446, 0.52958345, 0.18067934]], dtype=float32), -0.2746434]\n",
      "30 [array([[0.392821  , 0.54565424, 0.18604046]], dtype=float32), -0.28260195]\n",
      "35 [array([[0.39996022, 0.5558173 , 0.18941744]], dtype=float32), -0.28758383]\n",
      "40 [array([[0.4044857 , 0.56227785, 0.19155672]], dtype=float32), -0.29072213]\n",
      "45 [array([[0.4073647 , 0.56639796, 0.19291689]], dtype=float32), -0.29270762]\n",
      "50 [array([[0.40889612, 0.56859374, 0.19364004]], dtype=float32), -0.29375905]\n"
     ]
    }
   ],
   "source": [
    "num_iters = 50\n",
    "g = tf.Graph()\n",
    "wb = []\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]], dtype=tf.float32, name='W')\n",
    "        b = tf.Variable(0, dtype=tf.float32, name='b')\n",
    "        y_pred = tf.matmul(w, tf.transpose(x))+b\n",
    "        \n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        \n",
    "    with tf.name_scope('training') as scope:\n",
    "        lr = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for step in range(num_iters):\n",
    "            sess.run(train, {x:x_data, y_true:y_data})\n",
    "            if(step%5==0):\n",
    "                print(step, sess.run([w,b]))\n",
    "                wb.append(sess.run([w,b]))\n",
    "                \n",
    "        print(50, sess.run([w,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Softmax Regression with MNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ![](mnist.png)\n",
    "*<p style='text-align:right'>By Josef Steppan (Own work), via Wikimedia Commons</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '/data'\n",
    "num_iters = 1000\n",
    "minibatch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data\\train-images-idx3-ubyte.gz\n",
      "Extracting /data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /data\\t10k-labels-idx1-ubyte.gz\n",
      "Accuracy: 91.66%\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(datadir, one_hot=True)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "y_pred = tf.matmul(x, W)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(num_iters):\n",
    "        batch_xs, batch_ys = data.train.next_batch(minibatch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "        \n",
    "    testing = sess.run(accuracy, feed_dict={x:data.test.images, y_true:data.test.labels})\n",
    "    \n",
    "print('Accuracy: {:.4}%'.format(testing*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Helper Functions\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def conv_layer(input, shape):\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input, W)+b)\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = weight_variable([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W)+b \n",
    "\n",
    "### The Model (A CNN Approach)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784]) \n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "conv1 = conv_layer(x_image, shape=[5,5,1,32])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "conv2 = conv_layer(conv1_pool, shape=[5,5,32,64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1,7*7*64])\n",
    "\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "y_conv = full_layer(full1_drop, 10)\n",
    "\n",
    "mnist = input_data.read_data_sets(datadir, one_hot=True)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85517861 -0.21548274  0.6444358  -0.10079988 -0.78606453  0.18190946\n",
      "  -0.76554039 -0.41945907  1.67525144]\n",
      " [-0.1896261   0.28087765  1.35951643 -0.96064056  0.72667259  0.92944932\n",
      "   0.12309516  1.96124824 -0.05697205]\n",
      " [ 0.42001756  1.72626952  2.88989338  0.14850762 -0.30657997 -2.40677232\n",
      "  -0.59435295  2.58680778  0.04350803]\n",
      " [-1.66112881 -0.85911901  1.59722591 -0.19435795 -0.62307969 -0.97914755\n",
      "   1.89224924 -0.99496918 -0.33955149]]\n",
      "[[-0.52530402]\n",
      " [ 0.73122642]\n",
      " [-0.70642375]\n",
      " [-0.94313753]\n",
      " [ 0.51149802]\n",
      " [-0.6594694 ]\n",
      " [-1.35141269]\n",
      " [-0.86929466]\n",
      " [-0.20274482]]\n",
      "Output: -1.4294602870941162\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.03999999910593033\n",
      "step 10, training accuracy 0.18000000715255737\n",
      "step 20, training accuracy 0.5600000023841858\n",
      "step 30, training accuracy 0.47999998927116394\n",
      "step 40, training accuracy 0.7400000095367432\n",
      "step 50, training accuracy 0.6800000071525574\n",
      "step 60, training accuracy 0.8600000143051147\n",
      "step 70, training accuracy 0.8399999737739563\n",
      "step 80, training accuracy 0.7599999904632568\n",
      "step 90, training accuracy 0.7799999713897705\n",
      "step 100, training accuracy 0.8799999952316284\n",
      "step 110, training accuracy 0.800000011920929\n",
      "step 120, training accuracy 0.8799999952316284\n",
      "step 130, training accuracy 0.8999999761581421\n",
      "step 140, training accuracy 0.8999999761581421\n",
      "step 150, training accuracy 0.9200000166893005\n",
      "step 160, training accuracy 0.8799999952316284\n",
      "step 170, training accuracy 0.9399999976158142\n",
      "test accuracy: 0.9029000401496887\n"
     ]
    }
   ],
   "source": [
    "steps=180 \n",
    "                                                             \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch = mnist.train.next_batch(50) \n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: batch[0],y_: batch[1],keep_prob: 1.0}) \n",
    "            print (\"step {}, training accuracy {}\".format(i, train_accuracy)) \n",
    "        sess.run(train_step, feed_dict={x: batch[0], y_: batch[1],keep_prob: 0.5}) \n",
    "\n",
    "        \n",
    "    X = mnist.test.images.reshape(10, 1000, 784)\n",
    "    Y = mnist.test.labels.reshape(10, 1000, 10) \n",
    "    test_accuracy = np.mean([sess.run(accuracy,feed_dict={x:X[i], y_:Y[i],keep_prob:1.0}) for i in range(10)])\n",
    "\n",
    "    \n",
    "print (\"test accuracy: {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
