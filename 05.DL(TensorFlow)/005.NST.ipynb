{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Neural Style Transfer</center>\n",
    "Neural Style Transfer (NST) refers as a class of software algorithm manipulate digital images, or videos, or adopt the appearance or visual style of another image.\n",
    "![](_img/StarryNight-small.jpg) \n",
    "\n",
    "*<p style=\"text-align:right\">By Vincent van Gogh [Public domain] via Wikimedia Commons</p>*\n",
    "\n",
    "![](_img/Marilyn_Monroe_in_1952-small.jpg)\n",
    "\n",
    "*<p style=\"text-align:right\">By English: New York Sunday News [Public domain], via Wikimedia Commons</p>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Cookbook:\n",
    "\n",
    "Antonio Gulli and Amita Kapoor - TensorFlow Deep Learning Cookbook - https://www.amazon.com/gp/product/B0753KP6S4/\n",
    "\n",
    "#### Gatys et al. (2015) paper:\n",
    "\n",
    "A Neural Algorithm of Artistic Style - https://arxiv.org/pdf/1508.06576.pdf\n",
    "\n",
    "\n",
    "#### Pretrained VGG19:\n",
    "\n",
    "http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
    "\n",
    "Images:\n",
    "\n",
    "- By Vincent van Gogh [Public domain] via Wikimedia Commons - https://en.wikipedia.org/wiki/File:VanGogh-starry_night_ballance1.jpg\n",
    "\n",
    "\n",
    "- New York Sunday News [Public domain], via Wikimedia Commons - https://upload.wikimedia.org/wikipedia/commons/0/0a/Marilyn_Monroe_in_1952.jpg\n",
    "\n",
    "#### Libraries:\n",
    "\n",
    "- tensorflow\n",
    "- numpy\n",
    "- scipy\n",
    "- PIL\n",
    "- matplotlib\n",
    "- possibly others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9d1bbafb27f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'output/'\n",
    "STYLE_IMAGE = 'data/StarryNight.jpg'\n",
    "CONTENT_IMAGE = 'data/Marilyn_Monroe_in_1952.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-13555b877f15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mALPHA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mVGG_MODEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/imagenet-vgg-verydeep-19.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mMEAN_VALUES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m123.68\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m116.779\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m103.939\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "NOISE_RATIO = 0.6\n",
    "BETA = 5\n",
    "ALPHA = 100\n",
    "VGG_MODEL = 'data/imagenet-vgg-verydeep-19.mat'\n",
    "MEAN_VALUES = np.array([123.68,116.779,103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = scipy.misc.imread(CONTENT_IMAGE)\n",
    "imshow(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image = scipy.misc.imread(STYLE_IMAGE)\n",
    "target_shape = content_image.shape\n",
    "style_image = scipy.misc.imresize(style_image, target_shape)\n",
    "scipy.misc.imsave(STYLE_IMAGE, style_image)\n",
    "imshow(style_image)\n",
    "print('The shape of the target is: ', target_shape)\n",
    "print('The shape of the style image is: ', style_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## VGG19 Architecture \n",
    "\n",
    "<br> \n",
    " \n",
    "![](vgg19arch.png) \n",
    "<br>\n",
    "\n",
    "<p style=\"text-align:right\">Image courtesy of (and adapted from) Simonyan and Zisserman - https://arxiv.org/pdf/1409.1556.pdf\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg_model(path, image_height, image_width, color_channel):\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer, expected_layer_name):\n",
    "        W = vgg_layers[0][layer][0][0][0][0]\n",
    "        b = vgg_layers[0][layer][0][0][0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][-2]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W,b\n",
    "    \n",
    "    def _relu(conv2d_layer):\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "    \n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b,(b.size)))\n",
    "        return tf.nn.conv2d(prev_layer,filter=W, strides=[1,1,1,1], padding='SAME')+b\n",
    "    \n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "    \n",
    "    def _avgpool(prev_layer):\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    graph = {}\n",
    "    graph['input'] = tf.Variable(np.zeros((1,image_height,image_width,color_channel)), dtype='float32')\n",
    "    graph['conv1_1'] = _conv2d_relu(graph['input'],0,'conv1_1')\n",
    "    graph['conv1_2'] = _conv2d_relu(graph['conv1_1'],2,'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss_func(sess, model):\n",
    "    def _content_loss(p,x):\n",
    "        N = p.shape[3]\n",
    "        M = p.shape[1]*p.shape[2]\n",
    "        return (1/(4*N*M))*tf.reduce_sum(tf.pow(x-p,2))\n",
    "    return _content_loss(sess.run(model['conv4_2']), model['conv4_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [('conv1_1', 0.5), ('conv2_1', 1.0), ('conv3_1', 1.5), ('conv4_1', 3.0), ('conv5_1', 4.0)]\n",
    "\n",
    "def style_loss_func(sess, model):\n",
    "    def _gram_matrix(F,N,M):\n",
    "        Ft = tf.reshape(F, (M, N))\n",
    "        return tf.matmul(tf.transpose(Ft), Ft)\n",
    "\n",
    "    def _style_loss(a, x):\n",
    "        N = a.shape[3]\n",
    "        M = a.shape[1] * a.shape[2]\n",
    "        A = _gram_matrix(a,N,M)\n",
    "        G = _gram_matrix(x,N,M)\n",
    "        result = (1/(4*N**2*M**2))*tf.reduce_sum(tf.pow(G-A,2))\n",
    "        return result\n",
    "\n",
    "    E = [_style_loss(sess.run(model[layer_name]), model[layer_name]) for layer_name, _ in STYLE_LAYERS]\n",
    "    W = [w for _, w in STYLE_LAYERS]\n",
    "    loss = sum([W[l]*E[l] for l in range(len(STYLE_LAYERS))])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
