Feature Extraction:
-------------------

it is a technique to extract features from a corpus
or images.

in Text classification we need to extract feature from
a corpus and in image classificaion we need to extract
feature from images.
	X		Y
fo@od is # good!		good
food is tasty		good
quality is Good		good
service is poor		not good
it is too costly	not good
cheap quality		not good


document->it is simply a string representing a text.
corpus->it is a group of documents as list.

c=['food is good','food is tasty',doc3,doc4,...doc-n]

sklearn provides 2 approaches for feature extraction
1.CountVectorizer
2.TfidfVectorizer

Working of CountVectorizer:
Example:
doc1='food is # good! _@ 2019'
doc2='& Food # is * tasty'
doc3='quality is Good'
doc4='service is Poor poor means very poor'
doc5='it is too costly'
doc6='cheap quality'


step-1:change all documents in lower case.

doc1='food is # good! _@ 2019'
doc2='& food # is * tasty'
doc3='quality is good'
doc4='service is poor poor means very poor'
doc5='it is too costly'
doc6='cheap quality'

step-2:remove punctuation characters from all docs.

doc1='food is good 2019'
doc2='food is tasty'
doc3='quality is good'
doc4='service is poor poor means very poor'
doc5='it is too costly'
doc6='cheap quality'

step-3:remove all single letter words.

doc1='food is good 2019'
doc2='food is tasty'
doc3='quality is good'
doc4='service is poor poor means very poor'
doc5='it is too costly'
doc6='cheap quality'

step-4:if stop_words argument is provided,remove all
stop words from all docs.

doc1='food good 2019'
doc2='food tasty'
doc3='quality good'
doc4='service poor poor means poor'
doc5='costly'
doc6='cheap quality'

step-5:collect unique words from corpus
food,good,2019,tasty,quality,service,poor,means,cheap
,costly


step-6:arrange thsese words in natural order
2019,cheap,costly,food,good,means,poor,quality,service,tasty

these are feature names.

step-7:for each doc count frequency of these features

	2019 cheap costly food good means poor quality service tasty
doc1=	1     0	     0	    1	1    0     0    0       0        0
doc2=	0     0      0      1   0    0     0    0       0        1
doc3=	0     0      0      0   1    0     0    1       0        0
doc4=	0     0      0      0   0    1	   3    0       1   	 0
doc5=	0     0      1      0   0    0     0    0       0        0
doc6=   0     1      0      0   0    0     0    1       0        0

step-8:tranform() returns 2d arrays of this corpus
	[[1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 3, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0]]

Note:bydefault CV counts frequency of feature in each doc and
we may also use CV to check only absence and presence of feature

cv=CountVectorizer(stop_word='english',binary=True)
	
	[[1, 0, 0, 1, 1, 0, 0, 0, 0, 0],
        [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],
        [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],
        [0, 0, 0, 0, 0, 1, 1, 0, 1, 0],
        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 0, 0, 1, 0, 0]]



